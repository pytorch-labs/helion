Running all 4 kernels...


============================================================
Kernel: gemm
============================================================

Running gemm benchmark with 2 Helion implementations...

Running input shard 3/4: inputs 16 to 23 (of 31 total)
  0%|          | 0/8 [00:00<?, ?it/s]INFO:tritonbench.utils.triton_op:Took 0.01ms to get benchmark function for aten_matmul
INFO:tritonbench.utils.triton_op:Took 0.01ms to get benchmark function for triton_tutorial_matmul
INFO:tritonbench.utils.triton_op:Took 0.05ms to get benchmark function for matmul_partition_k
/home/willfeng/local/pytorch-nightly/torch/backends/cuda/__init__.py:131: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:78.)
  return torch._C._get_cublas_allow_tf32()
INFO:tritonbench.utils.triton_op:Took 0.00ms to get benchmark function for triton_ops_matmul
INFO:tritonbench.utils.triton_op:Took 9.20ms to get benchmark function for aten_tunableop_matmul
INFO:tritonbench.utils.triton_op:Took 48.30ms to get benchmark function for pt2_triton_matmul
INFO:tritonbench.utils.triton_op:Took 0.00ms to get benchmark function for streamk_matmul
INFO:tritonbench.utils.triton_op:Took 35.21ms to get benchmark function for pt2_cutlass_matmul
INFO:tritonbench.utils.triton_op:Took 0.04ms to get benchmark function for helion_matmul_tritonbench
[0s] Starting DifferentialEvolutionSearch with population=40, generations=20, crossover_rate=0.8
Removed 1 outliers from 131 samples
Removed 1 outliers from 619 samples
Removed 9 outliers from 670 samples
Removed 12 outliers from 662 samples
Removed 4 outliers from 446 samples
Removed 11 outliers from 658 samples
[4s] PTXASError compiling config: Config(block_sizes=[1024, 128, 16], loop_orders=[[1, 0]], l2_groupings=[32], range_unroll_factors=[2, 2], range_num_stages=[3, 1], range_multi_buffers=[True, False], range_flattens=[None, False], num_warps=32, num_stages=7, indexing='pointer', pid_type='persistent_interleaved')
[14s] Initial population: failed=5 min=0.1583 mid=1.3985 max=24.3465 best=Config(block_sizes=[128, 16, 128], loop_orders=[[1, 0]], l2_groupings=[1], range_unroll_factors=[0, 0], range_num_stages=[0, 3], range_multi_buffers=[None, True], range_flattens=[None, None], num_warps=8, num_stages=1, indexing='tensor_descriptor', pid_type='flat', range_warp_specializes=[])
[39s] Generation 2: replaced=19 min=0.1397 mid=0.4134 max=1.2437 best=Config(block_sizes=[32, 512, 64], loop_orders=[[0, 1]], l2_groupings=[1], range_unroll_factors=[0, 0], range_num_stages=[0, 0], range_multi_buffers=[None, None], range_flattens=[None, True], num_warps=32, num_stages=3, indexing='tensor_descriptor', pid_type='flat', range_warp_specializes=[])
[68s] Generation 3: replaced=12 min=0.1015 mid=0.3321 max=1.2437 best=Config(block_sizes=[128, 32, 128], loop_orders=[[1, 0]], l2_groupings=[64], range_unroll_factors=[3, 0], range_num_stages=[0, 3], range_multi_buffers=[True, True], range_flattens=[False, True], num_warps=8, num_stages=1, indexing='pointer', pid_type='persistent_interleaved')
[97s] Generation 4: replaced=11 min=0.0804 mid=0.2560 max=1.2437 best=Config(block_sizes=[256, 64, 32], loop_orders=[[0, 1]], l2_groupings=[4], range_unroll_factors=[0, 3], range_num_stages=[0, 3], range_multi_buffers=[None, None], range_flattens=[None, None], num_warps=8, num_stages=6, indexing='block_ptr', pid_type='flat', range_warp_specializes=[])
[122s] PTXASError compiling config: Config(block_sizes=[64, 1024, 128], loop_orders=[[0, 1]], l2_groupings=[16], range_unroll_factors=[0, 0], range_num_stages=[0, 1], range_multi_buffers=[None, False], range_flattens=[None, True], num_warps=32, num_stages=1, indexing='tensor_descriptor', pid_type='flat', range_warp_specializes=[])
[142s] Generation 5: replaced=12 min=0.0804 mid=0.2506 max=0.9332 best=Config(block_sizes=[256, 64, 32], loop_orders=[[0, 1]], l2_groupings=[4], range_unroll_factors=[0, 3], range_num_stages=[0, 3], range_multi_buffers=[None, None], range_flattens=[None, None], num_warps=8, num_stages=6, indexing='block_ptr', pid_type='flat', range_warp_specializes=[])
[156s] PTXASError compiling config: Config(block_sizes=[64, 1024, 32], loop_orders=[[0, 1]], l2_groupings=[1], range_unroll_factors=[0, 1], range_num_stages=[0, 0], range_multi_buffers=[None, True], range_flattens=[None, False], num_warps=32, num_stages=2, indexing='pointer', pid_type='flat', range_warp_specializes=[])
[218s] Timeout after 60s compiling Config(block_sizes=[128, 32, 64], loop_orders=[[0, 1]], l2_groupings=[2], range_unroll_factors=[4, 3], range_num_stages=[0, 4], range_multi_buffers=[False, True], range_flattens=[True, True], num_warps=4, num_stages=5, indexing='block_ptr', pid_type='persistent_interleaved')
[232s] Generation 6: replaced=8 min=0.0804 mid=0.2431 max=0.9332 best=Config(block_sizes=[256, 64, 32], loop_orders=[[0, 1]], l2_groupings=[4], range_unroll_factors=[0, 3], range_num_stages=[0, 3], range_multi_buffers=[None, None], range_flattens=[None, None], num_warps=8, num_stages=6, indexing='block_ptr', pid_type='flat', range_warp_specializes=[])
[236s] PTXASError compiling config: Config(block_sizes=[128, 512, 64], loop_orders=[[1, 0]], l2_groupings=[64], range_unroll_factors=[0, 0], range_num_stages=[0, 4], range_multi_buffers=[None, False], range_flattens=[None, None], num_warps=16, num_stages=2, indexing='block_ptr', pid_type='flat', range_warp_specializes=[])
[265s] Generation 7: replaced=12 min=0.0804 mid=0.2121 max=0.4129 best=Config(block_sizes=[256, 64, 32], loop_orders=[[0, 1]], l2_groupings=[4], range_unroll_factors=[0, 3], range_num_stages=[0, 3], range_multi_buffers=[None, None], range_flattens=[None, None], num_warps=8, num_stages=6, indexing='block_ptr', pid_type='flat', range_warp_specializes=[])
[302s] Generation 8: replaced=11 min=0.0804 mid=0.1820 max=0.3464 best=Config(block_sizes=[256, 64, 32], loop_orders=[[0, 1]], l2_groupings=[4], range_unroll_factors=[0, 3], range_num_stages=[0, 3], range_multi_buffers=[None, None], range_flattens=[None, None], num_warps=8, num_stages=6, indexing='block_ptr', pid_type='flat', range_warp_specializes=[])
[350s] Generation 9: replaced=15 min=0.0700 mid=0.1538 max=0.3334 best=Config(block_sizes=[64, 128, 64], loop_orders=[[1, 0]], l2_groupings=[1], range_unroll_factors=[3, 0], range_num_stages=[1, 4], range_multi_buffers=[None, True], range_flattens=[False, True], num_warps=4, num_stages=2, indexing='block_ptr', pid_type='persistent_interleaved')
[356s] PTXASError compiling config: Config(block_sizes=[128, 512, 64], loop_orders=[[1, 0]], l2_groupings=[64], range_unroll_factors=[0, 0], range_num_stages=[0, 2], range_multi_buffers=[None, False], range_flattens=[None, True], num_warps=32, num_stages=1, indexing='pointer', pid_type='flat', range_warp_specializes=[])
[396s] Generation 10: replaced=6 min=0.0700 mid=0.1395 max=0.3334 best=Config(block_sizes=[64, 128, 64], loop_orders=[[1, 0]], l2_groupings=[1], range_unroll_factors=[3, 0], range_num_stages=[1, 4], range_multi_buffers=[None, True], range_flattens=[False, True], num_warps=4, num_stages=2, indexing='block_ptr', pid_type='persistent_interleaved')
[406s] PTXASError compiling config: Config(block_sizes=[256, 512, 32], loop_orders=[[0, 1]], l2_groupings=[2], range_unroll_factors=[0, 1], range_num_stages=[0, 4], range_multi_buffers=[None, None], range_flattens=[None, False], num_warps=32, num_stages=4, indexing='pointer', pid_type='flat', range_warp_specializes=[])
[439s] PTXASError compiling config: Config(block_sizes=[64, 1024, 128], loop_orders=[[1, 0]], l2_groupings=[64], range_unroll_factors=[4, 0], range_num_stages=[0, 1], range_multi_buffers=[None, None], range_flattens=[True, True], num_warps=32, num_stages=1, indexing='tensor_descriptor', pid_type='persistent_interleaved')
[442s] Generation 11: replaced=12 min=0.0559 mid=0.1182 max=0.3334 best=Config(block_sizes=[64, 128, 64], loop_orders=[[0, 1]], l2_groupings=[32], range_unroll_factors=[0, 0], range_num_stages=[0, 3], range_multi_buffers=[None, None], range_flattens=[None, None], num_warps=4, num_stages=4, indexing='block_ptr', pid_type='flat', range_warp_specializes=[])
[452s] PTXASError compiling config: Config(block_sizes=[128, 512, 64], loop_orders=[[0, 1]], l2_groupings=[2], range_unroll_factors=[2, 1], range_num_stages=[0, 2], range_multi_buffers=[True, None], range_flattens=[None, False], num_warps=16, num_stages=5, indexing='pointer', pid_type='persistent_interleaved')
[487s] Generation 12: replaced=9 min=0.0492 mid=0.1047 max=0.2736 best=Config(block_sizes=[128, 128, 32], loop_orders=[[1, 0]], l2_groupings=[32], range_unroll_factors=[0, 0], range_num_stages=[0, 4], range_multi_buffers=[None, False], range_flattens=[None, None], num_warps=4, num_stages=5, indexing='block_ptr', pid_type='flat', range_warp_specializes=[])
[491s] PTXASError compiling config: Config(block_sizes=[512, 128, 128], loop_orders=[[1, 0]], l2_groupings=[4], range_unroll_factors=[3, 0], range_num_stages=[0, 4], range_multi_buffers=[None, None], range_flattens=[False, False], num_warps=32, num_stages=2, indexing='tensor_descriptor', pid_type='persistent_blocked')
[493s] PTXASError compiling config: Config(block_sizes=[128, 1024, 32], loop_orders=[[1, 0]], l2_groupings=[16], range_unroll_factors=[0, 0], range_num_stages=[0, 2], range_multi_buffers=[None, True], range_flattens=[None, None], num_warps=32, num_stages=1, indexing='pointer', pid_type='flat', range_warp_specializes=[])
[526s] Generation 13: replaced=10 min=0.0492 mid=0.1015 max=0.2736 best=Config(block_sizes=[128, 128, 32], loop_orders=[[1, 0]], l2_groupings=[32], range_unroll_factors=[0, 0], range_num_stages=[0, 4], range_multi_buffers=[None, False], range_flattens=[None, None], num_warps=4, num_stages=5, indexing='block_ptr', pid_type='flat', range_warp_specializes=[])
[551s] PTXASError compiling config: Config(block_sizes=[256, 512, 64], loop_orders=[[1, 0]], l2_groupings=[64], range_unroll_factors=[0, 0], range_num_stages=[0, 2], range_multi_buffers=[None, True], range_flattens=[None, False], num_warps=32, num_stages=7, indexing='pointer', pid_type='flat', range_warp_specializes=[])
[571s] Generation 14: replaced=5 min=0.0492 mid=0.0901 max=0.2736 best=Config(block_sizes=[128, 128, 32], loop_orders=[[1, 0]], l2_groupings=[32], range_unroll_factors=[0, 0], range_num_stages=[0, 4], range_multi_buffers=[None, False], range_flattens=[None, None], num_warps=4, num_stages=5, indexing='block_ptr', pid_type='flat', range_warp_specializes=[])
[604s] PTXASError compiling config: Config(block_sizes=[512, 128, 64], loop_orders=[[0, 1]], l2_groupings=[32], range_unroll_factors=[4, 0], range_num_stages=[3, 4], range_multi_buffers=[None, False], range_flattens=[True, True], num_warps=32, num_stages=2, indexing='tensor_descriptor', pid_type='persistent_blocked')
[610s] Generation 15: replaced=11 min=0.0492 mid=0.0856 max=0.1970 best=Config(block_sizes=[128, 128, 32], loop_orders=[[1, 0]], l2_groupings=[32], range_unroll_factors=[0, 0], range_num_stages=[0, 4], range_multi_buffers=[None, False], range_flattens=[None, None], num_warps=4, num_stages=5, indexing='block_ptr', pid_type='flat', range_warp_specializes=[])
[652s] Generation 16: replaced=9 min=0.0492 mid=0.0826 max=0.1794 best=Config(block_sizes=[128, 128, 32], loop_orders=[[1, 0]], l2_groupings=[32], range_unroll_factors=[0, 0], range_num_stages=[0, 4], range_multi_buffers=[None, False], range_flattens=[None, None], num_warps=4, num_stages=5, indexing='block_ptr', pid_type='flat', range_warp_specializes=[])
[673s] PTXASError compiling config: Config(block_sizes=[256, 512, 32], loop_orders=[[1, 0]], l2_groupings=[32], range_unroll_factors=[2, 0], range_num_stages=[3, 4], range_multi_buffers=[False, False], range_flattens=[True, False], num_warps=16, num_stages=5, indexing='tensor_descriptor', pid_type='persistent_interleaved')
[681s] PTXASError compiling config: Config(block_sizes=[256, 256, 64], loop_orders=[[0, 1]], l2_groupings=[64], range_unroll_factors=[0, 0], range_num_stages=[0, 3], range_multi_buffers=[None, True], range_flattens=[None, False], num_warps=32, num_stages=7, indexing='tensor_descriptor', pid_type='flat', range_warp_specializes=[])
[687s] Generation 17: replaced=4 min=0.0492 mid=0.0790 max=0.1794 best=Config(block_sizes=[128, 128, 32], loop_orders=[[1, 0]], l2_groupings=[32], range_unroll_factors=[0, 0], range_num_stages=[0, 4], range_multi_buffers=[None, False], range_flattens=[None, None], num_warps=4, num_stages=5, indexing='block_ptr', pid_type='flat', range_warp_specializes=[])
[697s] PTXASError compiling config: Config(block_sizes=[128, 512, 128], loop_orders=[[0, 1]], l2_groupings=[4], range_unroll_factors=[4, 1], range_num_stages=[2, 3], range_multi_buffers=[False, None], range_flattens=[None, False], num_warps=32, num_stages=3, indexing='pointer', pid_type='persistent_interleaved')
[730s] Generation 18: replaced=7 min=0.0492 mid=0.0756 max=0.1794 best=Config(block_sizes=[128, 128, 32], loop_orders=[[1, 0]], l2_groupings=[32], range_unroll_factors=[0, 0], range_num_stages=[0, 4], range_multi_buffers=[None, False], range_flattens=[None, None], num_warps=4, num_stages=5, indexing='block_ptr', pid_type='flat', range_warp_specializes=[])
[734s] PTXASError compiling config: Config(block_sizes=[256, 256, 64], loop_orders=[[1, 0]], l2_groupings=[64], range_unroll_factors=[0, 0], range_num_stages=[0, 3], range_multi_buffers=[None, None], range_flattens=[None, None], num_warps=32, num_stages=4, indexing='block_ptr', pid_type='flat', range_warp_specializes=[])
[738s] PTXASError compiling config: Config(block_sizes=[256, 512, 32], loop_orders=[[1, 0]], l2_groupings=[32], range_unroll_factors=[0, 0], range_num_stages=[0, 4], range_multi_buffers=[None, True], range_flattens=[None, False], num_warps=32, num_stages=2, indexing='block_ptr', pid_type='flat', range_warp_specializes=[])
[764s] Generation 19: replaced=6 min=0.0492 mid=0.0734 max=0.1794 best=Config(block_sizes=[128, 128, 32], loop_orders=[[1, 0]], l2_groupings=[32], range_unroll_factors=[0, 0], range_num_stages=[0, 4], range_multi_buffers=[None, False], range_flattens=[None, None], num_warps=4, num_stages=5, indexing='block_ptr', pid_type='flat', range_warp_specializes=[])
[764s] Autotuning complete in 764.3s after searching 1519 configs.
One can hardcode the best config and skip autotuning with:
    @helion.kernel(config=helion.Config(block_sizes=[128, 128, 32], loop_orders=[[1, 0]], l2_groupings=[32], range_unroll_factors=[0, 0], range_num_stages=[0, 4], range_multi_buffers=[None, False], range_flattens=[None, None], num_warps=4, num_stages=5, indexing='block_ptr', pid_type='flat', range_warp_specializes=[]))

INFO:helion.runtime.kernel:Output code: 
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _matmul_kernel(x, y, out, _BLOCK_SIZE_1: tl.constexpr, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_2: tl.constexpr):
    num_pid_m = tl.cdiv(2304, _BLOCK_SIZE_1)
    num_pid_n = tl.cdiv(2304, _BLOCK_SIZE_0)
    inner_2d_pid = tl.program_id(0)
    num_pid_in_group = 32 * num_pid_n
    group_id = inner_2d_pid // num_pid_in_group
    first_pid_m = group_id * 32
    group_size_m = min(num_pid_m - first_pid_m, 32)
    pid_0 = first_pid_m + inner_2d_pid % num_pid_in_group % group_size_m
    pid_1 = inner_2d_pid % num_pid_in_group // group_size_m
    offset_1 = pid_0 * _BLOCK_SIZE_1
    offset_0 = pid_1 * _BLOCK_SIZE_0
    acc = tl.full([_BLOCK_SIZE_0, _BLOCK_SIZE_1], 0.0, tl.float32)
    for offset_2 in tl.range(0, 2304, _BLOCK_SIZE_2, num_stages=4, disallow_acc_multi_buffer=True):
        acc_copy = acc
        acc_copy_0 = acc_copy
        load = tl.load(tl.make_block_ptr(x, [2304, 2304], [2304, 1], [offset_0, offset_2], [_BLOCK_SIZE_0, _BLOCK_SIZE_2], [1, 0]), boundary_check=[0, 1], padding_option='zero')
        load_1 = tl.load(tl.make_block_ptr(y, [2304, 2304], [1, 2304], [offset_2, offset_1], [_BLOCK_SIZE_2, _BLOCK_SIZE_1], [0, 1]), boundary_check=[0, 1], padding_option='zero')
        acc = tl.dot(load, load_1, acc=acc_copy_0, input_precision='tf32')
    v_0 = acc.to(tl.float16)
    tl.store(tl.make_block_ptr(out, [2304, 2304], [2304, 1], [offset_0, offset_1], [_BLOCK_SIZE_0, _BLOCK_SIZE_1], [1, 0]), v_0, boundary_check=[0, 1])

def matmul(x: torch.Tensor, y: torch.Tensor, epilogue: Callable[[torch.Tensor, list[torch.Tensor]], torch.Tensor]=lambda acc, tile: acc, *, _launcher=_default_launcher):
    m, k = x.size()
    k2, n = y.size()
    assert k == k2, f'size mismatch {k} != {k2}'
    out = torch.empty([m, n], dtype=torch.promote_types(x.dtype, y.dtype), device=x.device)
    _BLOCK_SIZE_1 = 128
    _BLOCK_SIZE_0 = 128
    _BLOCK_SIZE_2 = 32
    _launcher(_matmul_kernel, (triton.cdiv(2304, _BLOCK_SIZE_1) * triton.cdiv(2304, _BLOCK_SIZE_0),), x, y, out, _BLOCK_SIZE_1, _BLOCK_SIZE_0, _BLOCK_SIZE_2, num_warps=4, num_stages=5)
    return out
INFO:helion.runtime.kernel:Output code: 
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _matmul_kernel(x, y, out, _BLOCK_SIZE_1: tl.constexpr, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_2: tl.constexpr):
    num_pid_m = tl.cdiv(2304, _BLOCK_SIZE_1)
    num_pid_n = tl.cdiv(2304, _BLOCK_SIZE_0)
    inner_2d_pid = tl.program_id(0)
    num_pid_in_group = 32 * num_pid_n
    group_id = inner_2d_pid // num_pid_in_group
    first_pid_m = group_id * 32
    group_size_m = min(num_pid_m - first_pid_m, 32)
    pid_0 = first_pid_m + inner_2d_pid % num_pid_in_group % group_size_m
    pid_1 = inner_2d_pid % num_pid_in_group // group_size_m
    offset_1 = pid_0 * _BLOCK_SIZE_1
    offset_0 = pid_1 * _BLOCK_SIZE_0
    acc = tl.full([_BLOCK_SIZE_0, _BLOCK_SIZE_1], 0.0, tl.float32)
    for offset_2 in tl.range(0, 2304, _BLOCK_SIZE_2, num_stages=4, disallow_acc_multi_buffer=True):
        acc_copy = acc
        acc_copy_0 = acc_copy
        load = tl.load(tl.make_block_ptr(x, [2304, 2304], [2304, 1], [offset_0, offset_2], [_BLOCK_SIZE_0, _BLOCK_SIZE_2], [1, 0]), boundary_check=[0, 1], padding_option='zero')
        load_1 = tl.load(tl.make_block_ptr(y, [2304, 2304], [1, 2304], [offset_2, offset_1], [_BLOCK_SIZE_2, _BLOCK_SIZE_1], [0, 1]), boundary_check=[0, 1], padding_option='zero')
        acc = tl.dot(load, load_1, acc=acc_copy_0, input_precision='tf32')
    v_0 = acc.to(tl.float16)
    tl.store(tl.make_block_ptr(out, [2304, 2304], [2304, 1], [offset_0, offset_1], [_BLOCK_SIZE_0, _BLOCK_SIZE_1], [1, 0]), v_0, boundary_check=[0, 1])

def matmul(x: torch.Tensor, y: torch.Tensor, epilogue: Callable[[torch.Tensor, list[torch.Tensor]], torch.Tensor]=lambda acc, tile: acc, *, _launcher=_default_launcher):
    m, k = x.size()
    k2, n = y.size()
    assert k == k2, f'size mismatch {k} != {k2}'
    out = torch.empty([m, n], dtype=torch.promote_types(x.dtype, y.dtype), device=x.device)
    _BLOCK_SIZE_1 = 128
    _BLOCK_SIZE_0 = 128
    _BLOCK_SIZE_2 = 32
    _launcher(_matmul_kernel, (triton.cdiv(2304, _BLOCK_SIZE_1) * triton.cdiv(2304, _BLOCK_SIZE_0),), x, y, out, _BLOCK_SIZE_1, _BLOCK_SIZE_0, _BLOCK_SIZE_2, num_warps=4, num_stages=5)
    return out
INFO:helion.runtime.kernel:Output code: 
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _matmul_kernel(x, y, out, _BLOCK_SIZE_1: tl.constexpr, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_2: tl.constexpr):
    num_pid_m = tl.cdiv(2304, _BLOCK_SIZE_1)
    num_pid_n = tl.cdiv(2304, _BLOCK_SIZE_0)
    inner_2d_pid = tl.program_id(0)
    num_pid_in_group = 32 * num_pid_n
    group_id = inner_2d_pid // num_pid_in_group
    first_pid_m = group_id * 32
    group_size_m = min(num_pid_m - first_pid_m, 32)
    pid_0 = first_pid_m + inner_2d_pid % num_pid_in_group % group_size_m
    pid_1 = inner_2d_pid % num_pid_in_group // group_size_m
    offset_1 = pid_0 * _BLOCK_SIZE_1
    offset_0 = pid_1 * _BLOCK_SIZE_0
    acc = tl.full([_BLOCK_SIZE_0, _BLOCK_SIZE_1], 0.0, tl.float32)
    for offset_2 in tl.range(0, 2304, _BLOCK_SIZE_2, num_stages=4, disallow_acc_multi_buffer=True):
        acc_copy = acc
        acc_copy_0 = acc_copy
        load = tl.load(tl.make_block_ptr(x, [2304, 2304], [2304, 1], [offset_0, offset_2], [_BLOCK_SIZE_0, _BLOCK_SIZE_2], [1, 0]), boundary_check=[0, 1], padding_option='zero')
        load_1 = tl.load(tl.make_block_ptr(y, [2304, 2304], [1, 2304], [offset_2, offset_1], [_BLOCK_SIZE_2, _BLOCK_SIZE_1], [0, 1]), boundary_check=[0, 1], padding_option='zero')
        acc = tl.dot(load, load_1, acc=acc_copy_0, input_precision='tf32')
    v_0 = acc.to(tl.float16)
    tl.store(tl.make_block_ptr(out, [2304, 2304], [2304, 1], [offset_0, offset_1], [_BLOCK_SIZE_0, _BLOCK_SIZE_1], [1, 0]), v_0, boundary_check=[0, 1])

def matmul(x: torch.Tensor, y: torch.Tensor, epilogue: Callable[[torch.Tensor, list[torch.Tensor]], torch.Tensor]=lambda acc, tile: acc, *, _launcher=_default_launcher):
    m, k = x.size()
    k2, n = y.size()
    assert k == k2, f'size mismatch {k} != {k2}'
    out = torch.empty([m, n], dtype=torch.promote_types(x.dtype, y.dtype), device=x.device)
    _BLOCK_SIZE_1 = 128
    _BLOCK_SIZE_0 = 128
    _BLOCK_SIZE_2 = 32
    _launcher(_matmul_kernel, (triton.cdiv(2304, _BLOCK_SIZE_1) * triton.cdiv(2304, _BLOCK_SIZE_0),), x, y, out, _BLOCK_SIZE_1, _BLOCK_SIZE_0, _BLOCK_SIZE_2, num_warps=4, num_stages=5)
    return out
INFO:helion.runtime.kernel:Output code: 
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _matmul_kernel(x, y, out, _BLOCK_SIZE_1: tl.constexpr, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_2: tl.constexpr):
    num_pid_m = tl.cdiv(2304, _BLOCK_SIZE_1)
    num_pid_n = tl.cdiv(2304, _BLOCK_SIZE_0)
    inner_2d_pid = tl.program_id(0)
    num_pid_in_group = 32 * num_pid_n
    group_id = inner_2d_pid // num_pid_in_group
    first_pid_m = group_id * 32
    group_size_m = min(num_pid_m - first_pid_m, 32)
    pid_0 = first_pid_m + inner_2d_pid % num_pid_in_group % group_size_m
    pid_1 = inner_2d_pid % num_pid_in_group // group_size_m
    offset_1 = pid_0 * _BLOCK_SIZE_1
    offset_0 = pid_1 * _BLOCK_SIZE_0
    acc = tl.full([_BLOCK_SIZE_0, _BLOCK_SIZE_1], 0.0, tl.float32)
    for offset_2 in tl.range(0, 2304, _BLOCK_SIZE_2, num_stages=4, disallow_acc_multi_buffer=True):
        acc_copy = acc
        acc_copy_0 = acc_copy
        load = tl.load(tl.make_block_ptr(x, [2304, 2304], [2304, 1], [offset_0, offset_2], [_BLOCK_SIZE_0, _BLOCK_SIZE_2], [1, 0]), boundary_check=[0, 1], padding_option='zero')
        load_1 = tl.load(tl.make_block_ptr(y, [2304, 2304], [1, 2304], [offset_2, offset_1], [_BLOCK_SIZE_2, _BLOCK_SIZE_1], [0, 1]), boundary_check=[0, 1], padding_option='zero')
        acc = tl.dot(load, load_1, acc=acc_copy_0, input_precision='tf32')
    v_0 = acc.to(tl.float16)
    tl.store(tl.make_block_ptr(out, [2304, 2304], [2304, 1], [offset_0, offset_1], [_BLOCK_SIZE_0, _BLOCK_SIZE_1], [1, 0]), v_0, boundary_check=[0, 1])

def matmul(x: torch.Tensor, y: torch.Tensor, epilogue: Callable[[torch.Tensor, list[torch.Tensor]], torch.Tensor]=lambda acc, tile: acc, *, _launcher=_default_launcher):
    m, k = x.size()
    k2, n = y.size()
    assert k == k2, f'size mismatch {k} != {k2}'
    out = torch.empty([m, n], dtype=torch.promote_types(x.dtype, y.dtype), device=x.device)
    _BLOCK_SIZE_1 = 128
    _BLOCK_SIZE_0 = 128
    _BLOCK_SIZE_2 = 32
    _launcher(_matmul_kernel, (triton.cdiv(2304, _BLOCK_SIZE_1) * triton.cdiv(2304, _BLOCK_SIZE_0),), x, y, out, _BLOCK_SIZE_1, _BLOCK_SIZE_0, _BLOCK_SIZE_2, num_warps=4, num_stages=5)
    return out
INFO:helion.runtime.kernel:Output code: 
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _matmul_kernel(x, y, out, _BLOCK_SIZE_1: tl.constexpr, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_2: tl.constexpr):
    num_pid_m = tl.cdiv(2304, _BLOCK_SIZE_1)
    num_pid_n = tl.cdiv(2304, _BLOCK_SIZE_0)
    inner_2d_pid = tl.program_id(0)
    num_pid_in_group = 32 * num_pid_n
    group_id = inner_2d_pid // num_pid_in_group
    first_pid_m = group_id * 32
    group_size_m = min(num_pid_m - first_pid_m, 32)
    pid_0 = first_pid_m + inner_2d_pid % num_pid_in_group % group_size_m
    pid_1 = inner_2d_pid % num_pid_in_group // group_size_m
    offset_1 = pid_0 * _BLOCK_SIZE_1
    offset_0 = pid_1 * _BLOCK_SIZE_0
    acc = tl.full([_BLOCK_SIZE_0, _BLOCK_SIZE_1], 0.0, tl.float32)
    for offset_2 in tl.range(0, 2304, _BLOCK_SIZE_2, num_stages=4, disallow_acc_multi_buffer=True):
        acc_copy = acc
        acc_copy_0 = acc_copy
        load = tl.load(tl.make_block_ptr(x, [2304, 2304], [2304, 1], [offset_0, offset_2], [_BLOCK_SIZE_0, _BLOCK_SIZE_2], [1, 0]), boundary_check=[0, 1], padding_option='zero')
        load_1 = tl.load(tl.make_block_ptr(y, [2304, 2304], [1, 2304], [offset_2, offset_1], [_BLOCK_SIZE_2, _BLOCK_SIZE_1], [0, 1]), boundary_check=[0, 1], padding_option='zero')
        acc = tl.dot(load, load_1, acc=acc_copy_0, input_precision='tf32')
    v_0 = acc.to(tl.float16)
    tl.store(tl.make_block_ptr(out, [2304, 2304], [2304, 1], [offset_0, offset_1], [_BLOCK_SIZE_0, _BLOCK_SIZE_1], [1, 0]), v_0, boundary_check=[0, 1])

def matmul(x: torch.Tensor, y: torch.Tensor, epilogue: Callable[[torch.Tensor, list[torch.Tensor]], torch.Tensor]=lambda acc, tile: acc, *, _launcher=_default_launcher):
    m, k = x.size()
    k2, n = y.size()
    assert k == k2, f'size mismatch {k} != {k2}'
    out = torch.empty([m, n], dtype=torch.promote_types(x.dtype, y.dtype), device=x.device)
    _BLOCK_SIZE_1 = 128
    _BLOCK_SIZE_0 = 128
    _BLOCK_SIZE_2 = 32
    _launcher(_matmul_kernel, (triton.cdiv(2304, _BLOCK_SIZE_1) * triton.cdiv(2304, _BLOCK_SIZE_0),), x, y, out, _BLOCK_SIZE_1, _BLOCK_SIZE_0, _BLOCK_SIZE_2, num_warps=4, num_stages=5)
    return out
INFO:helion.runtime.kernel:Output code: 
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _matmul_kernel(x, y, out, _BLOCK_SIZE_1: tl.constexpr, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_2: tl.constexpr):
    num_pid_m = tl.cdiv(2304, _BLOCK_SIZE_1)
    num_pid_n = tl.cdiv(2304, _BLOCK_SIZE_0)
    inner_2d_pid = tl.program_id(0)
    num_pid_in_group = 32 * num_pid_n
    group_id = inner_2d_pid // num_pid_in_group
    first_pid_m = group_id * 32
    group_size_m = min(num_pid_m - first_pid_m, 32)
    pid_0 = first_pid_m + inner_2d_pid % num_pid_in_group % group_size_m
    pid_1 = inner_2d_pid % num_pid_in_group // group_size_m
    offset_1 = pid_0 * _BLOCK_SIZE_1
    offset_0 = pid_1 * _BLOCK_SIZE_0
    acc = tl.full([_BLOCK_SIZE_0, _BLOCK_SIZE_1], 0.0, tl.float32)
    for offset_2 in tl.range(0, 2304, _BLOCK_SIZE_2, num_stages=4, disallow_acc_multi_buffer=True):
        acc_copy = acc
        acc_copy_0 = acc_copy
        load = tl.load(tl.make_block_ptr(x, [2304, 2304], [2304, 1], [offset_0, offset_2], [_BLOCK_SIZE_0, _BLOCK_SIZE_2], [1, 0]), boundary_check=[0, 1], padding_option='zero')
        load_1 = tl.load(tl.make_block_ptr(y, [2304, 2304], [1, 2304], [offset_2, offset_1], [_BLOCK_SIZE_2, _BLOCK_SIZE_1], [0, 1]), boundary_check=[0, 1], padding_option='zero')
        acc = tl.dot(load, load_1, acc=acc_copy_0, input_precision='tf32')
    v_0 = acc.to(tl.float16)
    tl.store(tl.make_block_ptr(out, [2304, 2304], [2304, 1], [offset_0, offset_1], [_BLOCK_SIZE_0, _BLOCK_SIZE_1], [1, 0]), v_0, boundary_check=[0, 1])

def matmul(x: torch.Tensor, y: torch.Tensor, epilogue: Callable[[torch.Tensor, list[torch.Tensor]], torch.Tensor]=lambda acc, tile: acc, *, _launcher=_default_launcher):
    m, k = x.size()
    k2, n = y.size()
    assert k == k2, f'size mismatch {k} != {k2}'
    out = torch.empty([m, n], dtype=torch.promote_types(x.dtype, y.dtype), device=x.device)
    _BLOCK_SIZE_1 = 128
    _BLOCK_SIZE_0 = 128
    _BLOCK_SIZE_2 = 32
    _launcher(_matmul_kernel, (triton.cdiv(2304, _BLOCK_SIZE_1) * triton.cdiv(2304, _BLOCK_SIZE_0),), x, y, out, _BLOCK_SIZE_1, _BLOCK_SIZE_0, _BLOCK_SIZE_2, num_warps=4, num_stages=5)
    return out
INFO:helion.runtime.kernel:Output code: 
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _matmul_kernel(x, y, out, _BLOCK_SIZE_1: tl.constexpr, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_2: tl.constexpr):
    num_pid_m = tl.cdiv(2304, _BLOCK_SIZE_1)
    num_pid_n = tl.cdiv(2304, _BLOCK_SIZE_0)
    inner_2d_pid = tl.program_id(0)
    num_pid_in_group = 32 * num_pid_n
    group_id = inner_2d_pid // num_pid_in_group
    first_pid_m = group_id * 32
    group_size_m = min(num_pid_m - first_pid_m, 32)
    pid_0 = first_pid_m + inner_2d_pid % num_pid_in_group % group_size_m
    pid_1 = inner_2d_pid % num_pid_in_group // group_size_m
    offset_1 = pid_0 * _BLOCK_SIZE_1
    offset_0 = pid_1 * _BLOCK_SIZE_0
    acc = tl.full([_BLOCK_SIZE_0, _BLOCK_SIZE_1], 0.0, tl.float32)
    for offset_2 in tl.range(0, 2304, _BLOCK_SIZE_2, num_stages=4, disallow_acc_multi_buffer=True):
        acc_copy = acc
        acc_copy_0 = acc_copy
        load = tl.load(tl.make_block_ptr(x, [2304, 2304], [2304, 1], [offset_0, offset_2], [_BLOCK_SIZE_0, _BLOCK_SIZE_2], [1, 0]), boundary_check=[0, 1], padding_option='zero')
        load_1 = tl.load(tl.make_block_ptr(y, [2304, 2304], [1, 2304], [offset_2, offset_1], [_BLOCK_SIZE_2, _BLOCK_SIZE_1], [0, 1]), boundary_check=[0, 1], padding_option='zero')
        acc = tl.dot(load, load_1, acc=acc_copy_0, input_precision='tf32')
    v_0 = acc.to(tl.float16)
    tl.store(tl.make_block_ptr(out, [2304, 2304], [2304, 1], [offset_0, offset_1], [_BLOCK_SIZE_0, _BLOCK_SIZE_1], [1, 0]), v_0, boundary_check=[0, 1])

def matmul(x: torch.Tensor, y: torch.Tensor, epilogue: Callable[[torch.Tensor, list[torch.Tensor]], torch.Tensor]=lambda acc, tile: acc, *, _launcher=_default_launcher):
    m, k = x.size()
    k2, n = y.size()
    assert k == k2, f'size mismatch {k} != {k2}'
    out = torch.empty([m, n], dtype=torch.promote_types(x.dtype, y.dtype), device=x.device)
    _BLOCK_SIZE_1 = 128
    _BLOCK_SIZE_0 = 128
    _BLOCK_SIZE_2 = 32
    _launcher(_matmul_kernel, (triton.cdiv(2304, _BLOCK_SIZE_1) * triton.cdiv(2304, _BLOCK_SIZE_0),), x, y, out, _BLOCK_SIZE_1, _BLOCK_SIZE_0, _BLOCK_SIZE_2, num_warps=4, num_stages=5)
    return out
INFO:tritonbench.utils.triton_op:Took 0.02ms to get benchmark function for helion_matmul_split_k_tritonbench
[0s] Starting DifferentialEvolutionSearch with population=40, generations=20, crossover_rate=0.8
[16s] Initial population: failed=7 min=0.1576 mid=2.8356 max=31.9211 best=Config(block_sizes=[512, 64, 32], loop_orders=[[1, 2, 0]], l2_groupings=[64], range_unroll_factors=[0, 4], range_num_stages=[0, 1], range_multi_buffers=[None, False], range_flattens=[None, False], num_warps=32, num_stages=1, indexing='pointer', pid_type='flat', split_k=4, range_warp_specializes=[])
[49s] PTXASError compiling config: Config(block_sizes=[1024, 128, 16], loop_orders=[[1, 2, 0]], l2_groupings=[64], range_unroll_factors=[1, 4], range_num_stages=[2, 2], range_multi_buffers=[False, None], range_flattens=[True, None], num_warps=32, num_stages=1, indexing='tensor_descriptor', pid_type='persistent_blocked', split_k=16)
[51s] Generation 2: replaced=15 min=0.1411 mid=0.8468 max=2.9482 best=Config(block_sizes=[512, 64, 32], loop_orders=[[1, 2, 0]], l2_groupings=[64], range_unroll_factors=[1, 3], range_num_stages=[2, 0], range_multi_buffers=[True, True], range_flattens=[False, False], num_warps=16, num_stages=1, indexing='pointer', pid_type='persistent_interleaved', split_k=8)
[67s] PTXASError compiling config: Config(block_sizes=[512, 128, 64], loop_orders=[[0, 2, 1]], l2_groupings=[2], range_unroll_factors=[0, 3], range_num_stages=[3, 1], range_multi_buffers=[True, None], range_flattens=[True, False], num_warps=32, num_stages=2, indexing='tensor_descriptor', pid_type='persistent_blocked', split_k=2)
[85s] Generation 3: replaced=19 min=0.1105 mid=0.4991 max=1.2165 best=Config(block_sizes=[256, 32, 32], loop_orders=[[0, 1, 2]], l2_groupings=[16], range_unroll_factors=[0, 0], range_num_stages=[0, 4], range_multi_buffers=[None, None], range_flattens=[None, None], num_warps=2, num_stages=8, indexing='tensor_descriptor', pid_type='flat', split_k=4, range_warp_specializes=[])
[102s] PTXASError compiling config: Config(block_sizes=[512, 128, 16], loop_orders=[[1, 2, 0]], l2_groupings=[32], range_unroll_factors=[2, 4], range_num_stages=[1, 2], range_multi_buffers=[None, None], range_flattens=[None, True], num_warps=32, num_stages=1, indexing='block_ptr', pid_type='persistent_blocked', split_k=2)
[144s] Generation 4: replaced=15 min=0.0705 mid=0.3267 max=1.0743 best=Config(block_sizes=[128, 64, 128], loop_orders=[[2, 1, 0]], l2_groupings=[4], range_unroll_factors=[2, 1], range_num_stages=[1, 4], range_multi_buffers=[True, None], range_flattens=[True, None], num_warps=4, num_stages=3, indexing='tensor_descriptor', pid_type='persistent_interleaved', split_k=1)
[189s] Generation 5: replaced=13 min=0.0705 mid=0.2763 max=0.8807 best=Config(block_sizes=[128, 64, 128], loop_orders=[[2, 1, 0]], l2_groupings=[4], range_unroll_factors=[2, 1], range_num_stages=[1, 4], range_multi_buffers=[True, None], range_flattens=[True, None], num_warps=4, num_stages=3, indexing='tensor_descriptor', pid_type='persistent_interleaved', split_k=1)
[204s] PTXASError compiling config: Config(block_sizes=[512, 128, 32], loop_orders=[[2, 0, 1]], l2_groupings=[64], range_unroll_factors=[0, 3], range_num_stages=[1, 1], range_multi_buffers=[False, False], range_flattens=[True, None], num_warps=32, num_stages=3, indexing='block_ptr', pid_type='persistent_interleaved', split_k=2)
[240s] Generation 6: replaced=12 min=0.0705 mid=0.2552 max=0.8231 best=Config(block_sizes=[128, 64, 128], loop_orders=[[2, 1, 0]], l2_groupings=[4], range_unroll_factors=[2, 1], range_num_stages=[1, 4], range_multi_buffers=[True, None], range_flattens=[True, None], num_warps=4, num_stages=3, indexing='tensor_descriptor', pid_type='persistent_interleaved', split_k=1)
[248s] PTXASError compiling config: Config(block_sizes=[64, 1024, 128], loop_orders=[[1, 2, 0]], l2_groupings=[1], range_unroll_factors=[0, 2], range_num_stages=[3, 2], range_multi_buffers=[True, None], range_flattens=[True, False], num_warps=32, num_stages=3, indexing='tensor_descriptor', pid_type='persistent_interleaved', split_k=16)
[283s] Generation 7: replaced=10 min=0.0705 mid=0.2045 max=0.8231 best=Config(block_sizes=[128, 64, 128], loop_orders=[[2, 1, 0]], l2_groupings=[4], range_unroll_factors=[2, 1], range_num_stages=[1, 4], range_multi_buffers=[True, None], range_flattens=[True, None], num_warps=4, num_stages=3, indexing='tensor_descriptor', pid_type='persistent_interleaved', split_k=1)
[289s] PTXASError compiling config: Config(block_sizes=[512, 128, 16], loop_orders=[[1, 2, 0]], l2_groupings=[32], range_unroll_factors=[0, 4], range_num_stages=[4, 0], range_multi_buffers=[None, None], range_flattens=[None, None], num_warps=32, num_stages=2, indexing='tensor_descriptor', pid_type='persistent_blocked', split_k=8)
[330s] Generation 8: replaced=16 min=0.0705 mid=0.1581 max=0.3471 best=Config(block_sizes=[128, 64, 128], loop_orders=[[2, 1, 0]], l2_groupings=[4], range_unroll_factors=[2, 1], range_num_stages=[1, 4], range_multi_buffers=[True, None], range_flattens=[True, None], num_warps=4, num_stages=3, indexing='tensor_descriptor', pid_type='persistent_interleaved', split_k=1)
[348s] PTXASError compiling config: Config(block_sizes=[256, 256, 16], loop_orders=[[1, 2, 0]], l2_groupings=[32], range_unroll_factors=[0, 2], range_num_stages=[1, 2], range_multi_buffers=[False, True], range_flattens=[None, None], num_warps=16, num_stages=3, indexing='tensor_descriptor', pid_type='persistent_interleaved', split_k=4)
[350s] PTXASError compiling config: Config(block_sizes=[512, 256, 16], loop_orders=[[2, 0, 1]], l2_groupings=[8], range_unroll_factors=[0, 3], range_num_stages=[0, 2], range_multi_buffers=[None, False], range_flattens=[None, True], num_warps=16, num_stages=5, indexing='block_ptr', pid_type='flat', split_k=4, range_warp_specializes=[])
[372s] Generation 9: replaced=12 min=0.0705 mid=0.1487 max=0.3158 best=Config(block_sizes=[128, 64, 128], loop_orders=[[2, 1, 0]], l2_groupings=[4], range_unroll_factors=[2, 1], range_num_stages=[1, 4], range_multi_buffers=[True, None], range_flattens=[True, None], num_warps=4, num_stages=3, indexing='tensor_descriptor', pid_type='persistent_interleaved', split_k=1)
[379s] PTXASError compiling config: Config(block_sizes=[512, 256, 16], loop_orders=[[1, 0, 2]], l2_groupings=[4], range_unroll_factors=[0, 0], range_num_stages=[0, 1], range_multi_buffers=[None, None], range_flattens=[None, True], num_warps=32, num_stages=5, indexing='block_ptr', pid_type='flat', split_k=8, range_warp_specializes=[])
[402s] PTXASError compiling config: Config(block_sizes=[512, 256, 16], loop_orders=[[0, 1, 2]], l2_groupings=[8], range_unroll_factors=[1, 4], range_num_stages=[0, 4], range_multi_buffers=[None, None], range_flattens=[None, False], num_warps=32, num_stages=8, indexing='block_ptr', pid_type='persistent_blocked', split_k=16)
[407s] Generation 10: replaced=12 min=0.0705 mid=0.1238 max=0.2547 best=Config(block_sizes=[128, 64, 128], loop_orders=[[2, 1, 0]], l2_groupings=[4], range_unroll_factors=[2, 1], range_num_stages=[1, 4], range_multi_buffers=[True, None], range_flattens=[True, None], num_warps=4, num_stages=3, indexing='tensor_descriptor', pid_type='persistent_interleaved', split_k=1)
[412s] PTXASError compiling config: Config(block_sizes=[256, 256, 64], loop_orders=[[2, 1, 0]], l2_groupings=[4], range_unroll_factors=[0, 0], range_num_stages=[1, 3], range_multi_buffers=[True, False], range_flattens=[None, False], num_warps=16, num_stages=1, indexing='tensor_descriptor', pid_type='persistent_interleaved', split_k=8)
[440s] PTXASError compiling config: Config(block_sizes=[256, 256, 16], loop_orders=[[1, 2, 0]], l2_groupings=[2], range_unroll_factors=[0, 1], range_num_stages=[0, 3], range_multi_buffers=[None, True], range_flattens=[None, None], num_warps=16, num_stages=6, indexing='pointer', pid_type='flat', split_k=16, range_warp_specializes=[])
[440s] Generation 11: replaced=9 min=0.0588 mid=0.1111 max=0.2547 best=Config(block_sizes=[128, 128, 64], loop_orders=[[1, 0, 2]], l2_groupings=[2], range_unroll_factors=[0, 0], range_num_stages=[0, 3], range_multi_buffers=[None, None], range_flattens=[None, False], num_warps=8, num_stages=8, indexing='tensor_descriptor', pid_type='flat', split_k=4, range_warp_specializes=[])
[447s] PTXASError compiling config: Config(block_sizes=[256, 256, 64], loop_orders=[[2, 0, 1]], l2_groupings=[2], range_unroll_factors=[2, 0], range_num_stages=[0, 1], range_multi_buffers=[None, None], range_flattens=[None, False], num_warps=16, num_stages=1, indexing='pointer', pid_type='persistent_blocked', split_k=8)
[449s] PTXASError compiling config: Config(block_sizes=[256, 256, 32], loop_orders=[[1, 2, 0]], l2_groupings=[8], range_unroll_factors=[1, 1], range_num_stages=[1, 4], range_multi_buffers=[False, None], range_flattens=[False, None], num_warps=16, num_stages=5, indexing='tensor_descriptor', pid_type='persistent_blocked', split_k=8)
[455s] PTXASError compiling config: Config(block_sizes=[256, 256, 64], loop_orders=[[1, 0, 2]], l2_groupings=[4], range_unroll_factors=[1, 0], range_num_stages=[2, 2], range_multi_buffers=[None, False], range_flattens=[True, True], num_warps=32, num_stages=6, indexing='tensor_descriptor', pid_type='persistent_blocked', split_k=4)
[471s] Generation 12: replaced=14 min=0.0588 mid=0.1046 max=0.2459 best=Config(block_sizes=[128, 128, 64], loop_orders=[[1, 0, 2]], l2_groupings=[2], range_unroll_factors=[0, 0], range_num_stages=[0, 3], range_multi_buffers=[None, None], range_flattens=[None, False], num_warps=8, num_stages=8, indexing='tensor_descriptor', pid_type='flat', split_k=4, range_warp_specializes=[])
[477s] PTXASError compiling config: Config(block_sizes=[512, 256, 16], loop_orders=[[2, 0, 1]], l2_groupings=[16], range_unroll_factors=[0, 0], range_num_stages=[0, 2], range_multi_buffers=[None, True], range_flattens=[None, False], num_warps=32, num_stages=6, indexing='tensor_descriptor', pid_type='persistent_blocked', split_k=16)
[478s] PTXASError compiling config: Config(block_sizes=[256, 256, 32], loop_orders=[[1, 0, 2]], l2_groupings=[4], range_unroll_factors=[0, 1], range_num_stages=[0, 4], range_multi_buffers=[None, None], range_flattens=[None, False], num_warps=16, num_stages=2, indexing='pointer', pid_type='flat', split_k=4, range_warp_specializes=[])
[498s] PTXASError compiling config: Config(block_sizes=[256, 256, 16], loop_orders=[[1, 0, 2]], l2_groupings=[16], range_unroll_factors=[0, 2], range_num_stages=[0, 2], range_multi_buffers=[None, None], range_flattens=[None, None], num_warps=32, num_stages=4, indexing='pointer', pid_type='flat', split_k=4, range_warp_specializes=[])
[504s] Generation 13: replaced=12 min=0.0588 mid=0.0938 max=0.1837 best=Config(block_sizes=[128, 128, 64], loop_orders=[[1, 0, 2]], l2_groupings=[2], range_unroll_factors=[0, 0], range_num_stages=[0, 3], range_multi_buffers=[None, None], range_flattens=[None, False], num_warps=8, num_stages=8, indexing='tensor_descriptor', pid_type='flat', split_k=4, range_warp_specializes=[])
[508s] PTXASError compiling config: Config(block_sizes=[128, 512, 16], loop_orders=[[0, 1, 2]], l2_groupings=[1], range_unroll_factors=[1, 0], range_num_stages=[0, 4], range_multi_buffers=[True, None], range_flattens=[True, False], num_warps=16, num_stages=2, indexing='pointer', pid_type='persistent_blocked', split_k=8)
[510s] PTXASError compiling config: Config(block_sizes=[128, 512, 16], loop_orders=[[2, 1, 0]], l2_groupings=[32], range_unroll_factors=[0, 0], range_num_stages=[0, 4], range_multi_buffers=[None, None], range_flattens=[None, False], num_warps=16, num_stages=7, indexing='pointer', pid_type='flat', split_k=8, range_warp_specializes=[])
[524s] PTXASError compiling config: Config(block_sizes=[512, 256, 32], loop_orders=[[2, 0, 1]], l2_groupings=[32], range_unroll_factors=[0, 2], range_num_stages=[4, 1], range_multi_buffers=[True, True], range_flattens=[None, None], num_warps=16, num_stages=6, indexing='block_ptr', pid_type='persistent_interleaved', split_k=32)
[538s] Generation 14: replaced=14 min=0.0588 mid=0.0905 max=0.1630 best=Config(block_sizes=[128, 128, 64], loop_orders=[[1, 0, 2]], l2_groupings=[2], range_unroll_factors=[0, 0], range_num_stages=[0, 3], range_multi_buffers=[None, None], range_flattens=[None, False], num_warps=8, num_stages=8, indexing='tensor_descriptor', pid_type='flat', split_k=4, range_warp_specializes=[])
[553s] PTXASError compiling config: Config(block_sizes=[128, 512, 32], loop_orders=[[2, 0, 1]], l2_groupings=[1], range_unroll_factors=[0, 1], range_num_stages=[1, 4], range_multi_buffers=[None, None], range_flattens=[True, True], num_warps=16, num_stages=2, indexing='block_ptr', pid_type='persistent_blocked', split_k=2)
[556s] PTXASError compiling config: Config(block_sizes=[128, 512, 16], loop_orders=[[1, 0, 2]], l2_groupings=[1], range_unroll_factors=[0, 1], range_num_stages=[0, 2], range_multi_buffers=[None, None], range_flattens=[None, True], num_warps=16, num_stages=2, indexing='pointer', pid_type='flat', split_k=4, range_warp_specializes=[])
[560s] PTXASError compiling config: Config(block_sizes=[512, 256, 32], loop_orders=[[1, 0, 2]], l2_groupings=[16], range_unroll_factors=[2, 1], range_num_stages=[0, 3], range_multi_buffers=[None, None], range_flattens=[False, None], num_warps=32, num_stages=3, indexing='block_ptr', pid_type='persistent_blocked', split_k=8)
[572s] Generation 15: replaced=7 min=0.0588 mid=0.0835 max=0.1630 best=Config(block_sizes=[128, 128, 64], loop_orders=[[1, 0, 2]], l2_groupings=[2], range_unroll_factors=[0, 0], range_num_stages=[0, 3], range_multi_buffers=[None, None], range_flattens=[None, False], num_warps=8, num_stages=8, indexing='tensor_descriptor', pid_type='flat', split_k=4, range_warp_specializes=[])
[577s] PTXASError compiling config: Config(block_sizes=[128, 512, 32], loop_orders=[[0, 2, 1]], l2_groupings=[64], range_unroll_factors=[0, 0], range_num_stages=[2, 2], range_multi_buffers=[True, None], range_flattens=[False, None], num_warps=16, num_stages=8, indexing='tensor_descriptor', pid_type='persistent_blocked', split_k=2)
[579s] PTXASError compiling config: Config(block_sizes=[128, 512, 16], loop_orders=[[1, 0, 2]], l2_groupings=[2], range_unroll_factors=[2, 0], range_num_stages=[2, 2], range_multi_buffers=[True, False], range_flattens=[None, False], num_warps=16, num_stages=4, indexing='pointer', pid_type='persistent_interleaved', split_k=8)
[581s] PTXASError compiling config: Config(block_sizes=[128, 512, 64], loop_orders=[[2, 0, 1]], l2_groupings=[2], range_unroll_factors=[0, 0], range_num_stages=[0, 4], range_multi_buffers=[None, None], range_flattens=[None, True], num_warps=16, num_stages=2, indexing='tensor_descriptor', pid_type='flat', split_k=2, range_warp_specializes=[])
[584s] PTXASError compiling config: Config(block_sizes=[512, 256, 32], loop_orders=[[2, 0, 1]], l2_groupings=[8], range_unroll_factors=[0, 2], range_num_stages=[0, 1], range_multi_buffers=[None, None], range_flattens=[None, False], num_warps=16, num_stages=4, indexing='tensor_descriptor', pid_type='flat', split_k=4, range_warp_specializes=[])
[597s] PTXASError compiling config: Config(block_sizes=[256, 512, 16], loop_orders=[[2, 1, 0]], l2_groupings=[64], range_unroll_factors=[0, 1], range_num_stages=[0, 4], range_multi_buffers=[None, True], range_flattens=[None, True], num_warps=16, num_stages=5, indexing='tensor_descriptor', pid_type='flat', split_k=8, range_warp_specializes=[])
[601s] PTXASError compiling config: Config(block_sizes=[128, 512, 32], loop_orders=[[1, 0, 2]], l2_groupings=[32], range_unroll_factors=[0, 0], range_num_stages=[0, 2], range_multi_buffers=[False, None], range_flattens=[None, False], num_warps=32, num_stages=3, indexing='tensor_descriptor', pid_type='persistent_blocked', split_k=2)
[622s] Generation 16: replaced=9 min=0.0588 mid=0.0796 max=0.1242 best=Config(block_sizes=[128, 128, 64], loop_orders=[[1, 0, 2]], l2_groupings=[2], range_unroll_factors=[0, 0], range_num_stages=[0, 3], range_multi_buffers=[None, None], range_flattens=[None, False], num_warps=8, num_stages=8, indexing='tensor_descriptor', pid_type='flat', split_k=4, range_warp_specializes=[])
[642s] PTXASError compiling config: Config(block_sizes=[256, 512, 32], loop_orders=[[2, 0, 1]], l2_groupings=[1], range_unroll_factors=[0, 0], range_num_stages=[0, 4], range_multi_buffers=[None, True], range_flattens=[None, True], num_warps=16, num_stages=1, indexing='pointer', pid_type='flat', split_k=4, range_warp_specializes=[])
[645s] PTXASError compiling config: Config(block_sizes=[256, 1024, 16], loop_orders=[[1, 2, 0]], l2_groupings=[16], range_unroll_factors=[0, 0], range_num_stages=[0, 3], range_multi_buffers=[None, True], range_flattens=[None, False], num_warps=16, num_stages=5, indexing='block_ptr', pid_type='flat', split_k=1, range_warp_specializes=[])
[658s] PTXASError compiling config: Config(block_sizes=[128, 512, 32], loop_orders=[[1, 2, 0]], l2_groupings=[4], range_unroll_factors=[0, 0], range_num_stages=[0, 4], range_multi_buffers=[True, False], range_flattens=[None, False], num_warps=16, num_stages=1, indexing='tensor_descriptor', pid_type='persistent_blocked', split_k=2)
[660s] Generation 17: replaced=6 min=0.0588 mid=0.0780 max=0.1109 best=Config(block_sizes=[128, 128, 64], loop_orders=[[1, 0, 2]], l2_groupings=[2], range_unroll_factors=[0, 0], range_num_stages=[0, 3], range_multi_buffers=[None, None], range_flattens=[None, False], num_warps=8, num_stages=8, indexing='tensor_descriptor', pid_type='flat', split_k=4, range_warp_specializes=[])
[665s] PTXASError compiling config: Config(block_sizes=[128, 512, 64], loop_orders=[[2, 0, 1]], l2_groupings=[1], range_unroll_factors=[0, 0], range_num_stages=[0, 3], range_multi_buffers=[None, None], range_flattens=[None, True], num_warps=16, num_stages=1, indexing='block_ptr', pid_type='flat', split_k=2, range_warp_specializes=[])
[670s] PTXASError compiling config: Config(block_sizes=[256, 256, 32], loop_orders=[[0, 1, 2]], l2_groupings=[16], range_unroll_factors=[4, 0], range_num_stages=[0, 2], range_multi_buffers=[False, True], range_flattens=[True, None], num_warps=16, num_stages=1, indexing='block_ptr', pid_type='persistent_blocked', split_k=1)
[673s] PTXASError compiling config: Config(block_sizes=[128, 512, 32], loop_orders=[[2, 0, 1]], l2_groupings=[1], range_unroll_factors=[2, 0], range_num_stages=[3, 0], range_multi_buffers=[None, True], range_flattens=[True, None], num_warps=16, num_stages=2, indexing='block_ptr', pid_type='persistent_blocked', split_k=16)
[676s] PTXASError compiling config: Config(block_sizes=[256, 256, 16], loop_orders=[[2, 1, 0]], l2_groupings=[4], range_unroll_factors=[1, 1], range_num_stages=[1, 2], range_multi_buffers=[True, True], range_flattens=[None, None], num_warps=16, num_stages=7, indexing='tensor_descriptor', pid_type='persistent_interleaved', split_k=16)
[736s] Timeout after 60s compiling Config(block_sizes=[64, 256, 32], loop_orders=[[1, 0, 2]], l2_groupings=[2], range_unroll_factors=[0, 0], range_num_stages=[0, 4], range_multi_buffers=[None, None], range_flattens=[None, True], num_warps=4, num_stages=2, indexing='tensor_descriptor', pid_type='flat', split_k=2, range_warp_specializes=[])
[738s] PTXASError compiling config: Config(block_sizes=[256, 256, 16], loop_orders=[[0, 1, 2]], l2_groupings=[8], range_unroll_factors=[3, 1], range_num_stages=[0, 4], range_multi_buffers=[False, None], range_flattens=[None, True], num_warps=32, num_stages=6, indexing='tensor_descriptor', pid_type='persistent_blocked', split_k=4)
[739s] PTXASError compiling config: Config(block_sizes=[128, 512, 16], loop_orders=[[0, 2, 1]], l2_groupings=[8], range_unroll_factors=[1, 0], range_num_stages=[4, 3], range_multi_buffers=[True, None], range_flattens=[None, True], num_warps=16, num_stages=2, indexing='block_ptr', pid_type='persistent_blocked', split_k=1)
[759s] Generation 18: replaced=5 min=0.0588 mid=0.0765 max=0.1084 best=Config(block_sizes=[128, 128, 64], loop_orders=[[1, 0, 2]], l2_groupings=[2], range_unroll_factors=[0, 0], range_num_stages=[0, 3], range_multi_buffers=[None, None], range_flattens=[None, False], num_warps=8, num_stages=8, indexing='tensor_descriptor', pid_type='flat', split_k=4, range_warp_specializes=[])
[763s] PTXASError compiling config: Config(block_sizes=[256, 256, 32], loop_orders=[[1, 0, 2]], l2_groupings=[8], range_unroll_factors=[0, 1], range_num_stages=[0, 2], range_multi_buffers=[None, False], range_flattens=[None, False], num_warps=16, num_stages=4, indexing='block_ptr', pid_type='flat', split_k=2, range_warp_specializes=[])
[798s] Generation 19: replaced=6 min=0.0588 mid=0.0746 max=0.1038 best=Config(block_sizes=[128, 128, 64], loop_orders=[[1, 0, 2]], l2_groupings=[2], range_unroll_factors=[0, 0], range_num_stages=[0, 3], range_multi_buffers=[None, None], range_flattens=[None, False], num_warps=8, num_stages=8, indexing='tensor_descriptor', pid_type='flat', split_k=4, range_warp_specializes=[])
[798s] Autotuning complete in 798.8s after searching 1519 configs.
One can hardcode the best config and skip autotuning with:
    @helion.kernel(config=helion.Config(block_sizes=[128, 128, 64], loop_orders=[[1, 0, 2]], l2_groupings=[2], range_unroll_factors=[0, 0], range_num_stages=[0, 3], range_multi_buffers=[None, None], range_flattens=[None, False], num_warps=8, num_stages=8, indexing='tensor_descriptor', pid_type='flat', split_k=4, range_warp_specializes=[]))

INFO:helion.runtime.kernel:Output code: 
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

import examples.matmul_split_k as _source_module

@triton.jit
def _matmul_split_k_kernel(x, y, out, _BLOCK_SIZE_1: tl.constexpr, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_2: tl.constexpr, _BLOCK_SIZE_3: tl.constexpr):
    num_blocks_0 = tl.cdiv(2304, _BLOCK_SIZE_1)
    num_blocks_1 = tl.cdiv(2304, _BLOCK_SIZE_0)
    num_pid_m = tl.cdiv(2304, _BLOCK_SIZE_1)
    num_pid_n = tl.cdiv(2304, _BLOCK_SIZE_0)
    inner_2d_size = num_pid_m * num_pid_n
    inner_2d_pid = tl.program_id(0) % inner_2d_size
    num_pid_in_group = 2 * num_pid_n
    group_id = inner_2d_pid // num_pid_in_group
    first_pid_m = group_id * 2
    group_size_m = min(num_pid_m - first_pid_m, 2)
    pid_0 = first_pid_m + inner_2d_pid % num_pid_in_group % group_size_m
    pid_1 = inner_2d_pid % num_pid_in_group // group_size_m
    pid_2 = tl.program_id(0) // (num_blocks_0 * num_blocks_1)
    offset_1 = pid_0 * _BLOCK_SIZE_1
    indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
    offset_0 = pid_1 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    offset_2 = pid_2 * _BLOCK_SIZE_2
    acc = tl.full([_BLOCK_SIZE_0, _BLOCK_SIZE_1], 0.0, tl.float32)
    tile_end = tl.minimum(offset_2 + _BLOCK_SIZE_2, 2304)
    for offset_3 in tl.range(offset_2.to(tl.int32), tile_end.to(tl.int32), _BLOCK_SIZE_3, num_stages=3, flatten=False):
        indices_3 = offset_3 + tl.arange(0, _BLOCK_SIZE_3).to(tl.int32)
        mask_3 = indices_3 < tile_end
        acc_copy = acc
        acc_copy_0 = acc_copy
        load = tl.load(x + (indices_0[:, None] * 2304 + indices_3[None, :] * 1), mask_3[None, :], other=0)
        load_1 = tl.load(y + (indices_3[:, None] * 1 + indices_1[None, :] * 2304), mask_3[:, None], other=0)
        acc = tl.dot(load, load_1, acc=acc_copy_0, input_precision='tf32')
    eq = offset_2 == 0
    if eq:
        acc_copy_1 = acc
        acc = acc_copy_1
    tl.atomic_add(out + (indices_0[:, None] * 2304 + indices_1[None, :] * 1), acc, mask=None, sem='relaxed')

def matmul_split_k(x: torch.Tensor, y: torch.Tensor, epilogue: Callable[[torch.Tensor, list[torch.Tensor]], torch.Tensor]=lambda acc, tile: acc, *, _launcher=_default_launcher):
    m, k = x.size()
    k2, n = y.size()
    assert k == k2, f'size mismatch {k} != {k2}'
    out = torch.zeros([m, n], dtype=torch.promote_types(x.dtype, y.dtype), device=x.device)
    split_k = 4
    k_block = helion.next_power_of_2(helion.cdiv(k, split_k))
    _BLOCK_SIZE_1 = 128
    _BLOCK_SIZE_0 = 128
    _BLOCK_SIZE_2 = k_block
    _BLOCK_SIZE_3 = 64
    _launcher(_matmul_split_k_kernel, (triton.cdiv(2304, _BLOCK_SIZE_1) * triton.cdiv(2304, _BLOCK_SIZE_0) * triton.cdiv(2304, _BLOCK_SIZE_2),), x, y, out, _BLOCK_SIZE_1, _BLOCK_SIZE_0, _BLOCK_SIZE_2, _BLOCK_SIZE_3, num_warps=8, num_stages=8)
    return out
INFO:helion.runtime.kernel:Output code: 
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

import examples.matmul_split_k as _source_module

@triton.jit
def _matmul_split_k_kernel(x, y, out, _BLOCK_SIZE_1: tl.constexpr, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_2: tl.constexpr, _BLOCK_SIZE_3: tl.constexpr):
    num_blocks_0 = tl.cdiv(2304, _BLOCK_SIZE_1)
    num_blocks_1 = tl.cdiv(2304, _BLOCK_SIZE_0)
    num_pid_m = tl.cdiv(2304, _BLOCK_SIZE_1)
    num_pid_n = tl.cdiv(2304, _BLOCK_SIZE_0)
    inner_2d_size = num_pid_m * num_pid_n
    inner_2d_pid = tl.program_id(0) % inner_2d_size
    num_pid_in_group = 2 * num_pid_n
    group_id = inner_2d_pid // num_pid_in_group
    first_pid_m = group_id * 2
    group_size_m = min(num_pid_m - first_pid_m, 2)
    pid_0 = first_pid_m + inner_2d_pid % num_pid_in_group % group_size_m
    pid_1 = inner_2d_pid % num_pid_in_group // group_size_m
    pid_2 = tl.program_id(0) // (num_blocks_0 * num_blocks_1)
    offset_1 = pid_0 * _BLOCK_SIZE_1
    indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
    offset_0 = pid_1 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    offset_2 = pid_2 * _BLOCK_SIZE_2
    acc = tl.full([_BLOCK_SIZE_0, _BLOCK_SIZE_1], 0.0, tl.float32)
    tile_end = tl.minimum(offset_2 + _BLOCK_SIZE_2, 2304)
    for offset_3 in tl.range(offset_2.to(tl.int32), tile_end.to(tl.int32), _BLOCK_SIZE_3, num_stages=3, flatten=False):
        indices_3 = offset_3 + tl.arange(0, _BLOCK_SIZE_3).to(tl.int32)
        mask_3 = indices_3 < tile_end
        acc_copy = acc
        acc_copy_0 = acc_copy
        load = tl.load(x + (indices_0[:, None] * 2304 + indices_3[None, :] * 1), mask_3[None, :], other=0)
        load_1 = tl.load(y + (indices_3[:, None] * 1 + indices_1[None, :] * 2304), mask_3[:, None], other=0)
        acc = tl.dot(load, load_1, acc=acc_copy_0, input_precision='tf32')
    eq = offset_2 == 0
    if eq:
        acc_copy_1 = acc
        acc = acc_copy_1
    tl.atomic_add(out + (indices_0[:, None] * 2304 + indices_1[None, :] * 1), acc, mask=None, sem='relaxed')

def matmul_split_k(x: torch.Tensor, y: torch.Tensor, epilogue: Callable[[torch.Tensor, list[torch.Tensor]], torch.Tensor]=lambda acc, tile: acc, *, _launcher=_default_launcher):
    m, k = x.size()
    k2, n = y.size()
    assert k == k2, f'size mismatch {k} != {k2}'
    out = torch.zeros([m, n], dtype=torch.promote_types(x.dtype, y.dtype), device=x.device)
    split_k = 4
    k_block = helion.next_power_of_2(helion.cdiv(k, split_k))
    _BLOCK_SIZE_1 = 128
    _BLOCK_SIZE_0 = 128
    _BLOCK_SIZE_2 = k_block
    _BLOCK_SIZE_3 = 64
    _launcher(_matmul_split_k_kernel, (triton.cdiv(2304, _BLOCK_SIZE_1) * triton.cdiv(2304, _BLOCK_SIZE_0) * triton.cdiv(2304, _BLOCK_SIZE_2),), x, y, out, _BLOCK_SIZE_1, _BLOCK_SIZE_0, _BLOCK_SIZE_2, _BLOCK_SIZE_3, num_warps=8, num_stages=8)
    return out
INFO:helion.runtime.kernel:Output code: 
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

import examples.matmul_split_k as _source_module

@triton.jit
def _matmul_split_k_kernel(x, y, out, _BLOCK_SIZE_1: tl.constexpr, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_2: tl.constexpr, _BLOCK_SIZE_3: tl.constexpr):
    num_blocks_0 = tl.cdiv(2304, _BLOCK_SIZE_1)
    num_blocks_1 = tl.cdiv(2304, _BLOCK_SIZE_0)
    num_pid_m = tl.cdiv(2304, _BLOCK_SIZE_1)
    num_pid_n = tl.cdiv(2304, _BLOCK_SIZE_0)
    inner_2d_size = num_pid_m * num_pid_n
    inner_2d_pid = tl.program_id(0) % inner_2d_size
    num_pid_in_group = 2 * num_pid_n
    group_id = inner_2d_pid // num_pid_in_group
    first_pid_m = group_id * 2
    group_size_m = min(num_pid_m - first_pid_m, 2)
    pid_0 = first_pid_m + inner_2d_pid % num_pid_in_group % group_size_m
    pid_1 = inner_2d_pid % num_pid_in_group // group_size_m
    pid_2 = tl.program_id(0) // (num_blocks_0 * num_blocks_1)
    offset_1 = pid_0 * _BLOCK_SIZE_1
    indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
    offset_0 = pid_1 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    offset_2 = pid_2 * _BLOCK_SIZE_2
    acc = tl.full([_BLOCK_SIZE_0, _BLOCK_SIZE_1], 0.0, tl.float32)
    tile_end = tl.minimum(offset_2 + _BLOCK_SIZE_2, 2304)
    for offset_3 in tl.range(offset_2.to(tl.int32), tile_end.to(tl.int32), _BLOCK_SIZE_3, num_stages=3, flatten=False):
        indices_3 = offset_3 + tl.arange(0, _BLOCK_SIZE_3).to(tl.int32)
        mask_3 = indices_3 < tile_end
        acc_copy = acc
        acc_copy_0 = acc_copy
        load = tl.load(x + (indices_0[:, None] * 2304 + indices_3[None, :] * 1), mask_3[None, :], other=0)
        load_1 = tl.load(y + (indices_3[:, None] * 1 + indices_1[None, :] * 2304), mask_3[:, None], other=0)
        acc = tl.dot(load, load_1, acc=acc_copy_0, input_precision='tf32')
    eq = offset_2 == 0
    if eq:
        acc_copy_1 = acc
        acc = acc_copy_1
    tl.atomic_add(out + (indices_0[:, None] * 2304 + indices_1[None, :] * 1), acc, mask=None, sem='relaxed')

def matmul_split_k(x: torch.Tensor, y: torch.Tensor, epilogue: Callable[[torch.Tensor, list[torch.Tensor]], torch.Tensor]=lambda acc, tile: acc, *, _launcher=_default_launcher):
    m, k = x.size()
    k2, n = y.size()
    assert k == k2, f'size mismatch {k} != {k2}'
    out = torch.zeros([m, n], dtype=torch.promote_types(x.dtype, y.dtype), device=x.device)
    split_k = 4
    k_block = helion.next_power_of_2(helion.cdiv(k, split_k))
    _BLOCK_SIZE_1 = 128
    _BLOCK_SIZE_0 = 128
    _BLOCK_SIZE_2 = k_block
    _BLOCK_SIZE_3 = 64
    _launcher(_matmul_split_k_kernel, (triton.cdiv(2304, _BLOCK_SIZE_1) * triton.cdiv(2304, _BLOCK_SIZE_0) * triton.cdiv(2304, _BLOCK_SIZE_2),), x, y, out, _BLOCK_SIZE_1, _BLOCK_SIZE_0, _BLOCK_SIZE_2, _BLOCK_SIZE_3, num_warps=8, num_stages=8)
    return out
INFO:helion.runtime.kernel:Output code: 
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

import examples.matmul_split_k as _source_module

@triton.jit
def _matmul_split_k_kernel(x, y, out, _BLOCK_SIZE_1: tl.constexpr, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_2: tl.constexpr, _BLOCK_SIZE_3: tl.constexpr):
    num_blocks_0 = tl.cdiv(2304, _BLOCK_SIZE_1)
    num_blocks_1 = tl.cdiv(2304, _BLOCK_SIZE_0)
    num_pid_m = tl.cdiv(2304, _BLOCK_SIZE_1)
    num_pid_n = tl.cdiv(2304, _BLOCK_SIZE_0)
    inner_2d_size = num_pid_m * num_pid_n
    inner_2d_pid = tl.program_id(0) % inner_2d_size
    num_pid_in_group = 2 * num_pid_n
    group_id = inner_2d_pid // num_pid_in_group
    first_pid_m = group_id * 2
    group_size_m = min(num_pid_m - first_pid_m, 2)
    pid_0 = first_pid_m + inner_2d_pid % num_pid_in_group % group_size_m
    pid_1 = inner_2d_pid % num_pid_in_group // group_size_m
    pid_2 = tl.program_id(0) // (num_blocks_0 * num_blocks_1)
    offset_1 = pid_0 * _BLOCK_SIZE_1
    indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
    offset_0 = pid_1 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    offset_2 = pid_2 * _BLOCK_SIZE_2
    acc = tl.full([_BLOCK_SIZE_0, _BLOCK_SIZE_1], 0.0, tl.float32)
    tile_end = tl.minimum(offset_2 + _BLOCK_SIZE_2, 2304)
    for offset_3 in tl.range(offset_2.to(tl.int32), tile_end.to(tl.int32), _BLOCK_SIZE_3, num_stages=3, flatten=False):
        indices_3 = offset_3 + tl.arange(0, _BLOCK_SIZE_3).to(tl.int32)
        mask_3 = indices_3 < tile_end
        acc_copy = acc
        acc_copy_0 = acc_copy
        load = tl.load(x + (indices_0[:, None] * 2304 + indices_3[None, :] * 1), mask_3[None, :], other=0)
        load_1 = tl.load(y + (indices_3[:, None] * 1 + indices_1[None, :] * 2304), mask_3[:, None], other=0)
        acc = tl.dot(load, load_1, acc=acc_copy_0, input_precision='tf32')
    eq = offset_2 == 0
    if eq:
        acc_copy_1 = acc
        acc = acc_copy_1
    tl.atomic_add(out + (indices_0[:, None] * 2304 + indices_1[None, :] * 1), acc, mask=None, sem='relaxed')

def matmul_split_k(x: torch.Tensor, y: torch.Tensor, epilogue: Callable[[torch.Tensor, list[torch.Tensor]], torch.Tensor]=lambda acc, tile: acc, *, _launcher=_default_launcher):
    m, k = x.size()
    k2, n = y.size()
    assert k == k2, f'size mismatch {k} != {k2}'
    out = torch.zeros([m, n], dtype=torch.promote_types(x.dtype, y.dtype), device=x.device)
    split_k = 4
    k_block = helion.next_power_of_2(helion.cdiv(k, split_k))
    _BLOCK_SIZE_1 = 128
    _BLOCK_SIZE_0 = 128
    _BLOCK_SIZE_2 = k_block
    _BLOCK_SIZE_3 = 64
    _launcher(_matmul_split_k_kernel, (triton.cdiv(2304, _BLOCK_SIZE_1) * triton.cdiv(2304, _BLOCK_SIZE_0) * triton.cdiv(2304, _BLOCK_SIZE_2),), x, y, out, _BLOCK_SIZE_1, _BLOCK_SIZE_0, _BLOCK_SIZE_2, _BLOCK_SIZE_3, num_warps=8, num_stages=8)
    return out
INFO:helion.runtime.kernel:Output code: 
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

import examples.matmul_split_k as _source_module

@triton.jit
def _matmul_split_k_kernel(x, y, out, _BLOCK_SIZE_1: tl.constexpr, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_2: tl.constexpr, _BLOCK_SIZE_3: tl.constexpr):
    num_blocks_0 = tl.cdiv(2304, _BLOCK_SIZE_1)
    num_blocks_1 = tl.cdiv(2304, _BLOCK_SIZE_0)
    num_pid_m = tl.cdiv(2304, _BLOCK_SIZE_1)
    num_pid_n = tl.cdiv(2304, _BLOCK_SIZE_0)
    inner_2d_size = num_pid_m * num_pid_n
    inner_2d_pid = tl.program_id(0) % inner_2d_size
    num_pid_in_group = 2 * num_pid_n
    group_id = inner_2d_pid // num_pid_in_group
    first_pid_m = group_id * 2
    group_size_m = min(num_pid_m - first_pid_m, 2)
    pid_0 = first_pid_m + inner_2d_pid % num_pid_in_group % group_size_m
    pid_1 = inner_2d_pid % num_pid_in_group // group_size_m
    pid_2 = tl.program_id(0) // (num_blocks_0 * num_blocks_1)
    offset_1 = pid_0 * _BLOCK_SIZE_1
    indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
    offset_0 = pid_1 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    offset_2 = pid_2 * _BLOCK_SIZE_2
    acc = tl.full([_BLOCK_SIZE_0, _BLOCK_SIZE_1], 0.0, tl.float32)
    tile_end = tl.minimum(offset_2 + _BLOCK_SIZE_2, 2304)
    for offset_3 in tl.range(offset_2.to(tl.int32), tile_end.to(tl.int32), _BLOCK_SIZE_3, num_stages=3, flatten=False):
        indices_3 = offset_3 + tl.arange(0, _BLOCK_SIZE_3).to(tl.int32)
        mask_3 = indices_3 < tile_end
        acc_copy = acc
        acc_copy_0 = acc_copy
        load = tl.load(x + (indices_0[:, None] * 2304 + indices_3[None, :] * 1), mask_3[None, :], other=0)
        load_1 = tl.load(y + (indices_3[:, None] * 1 + indices_1[None, :] * 2304), mask_3[:, None], other=0)
        acc = tl.dot(load, load_1, acc=acc_copy_0, input_precision='tf32')
    eq = offset_2 == 0
    if eq:
        acc_copy_1 = acc
        acc = acc_copy_1
    tl.atomic_add(out + (indices_0[:, None] * 2304 + indices_1[None, :] * 1), acc, mask=None, sem='relaxed')

def matmul_split_k(x: torch.Tensor, y: torch.Tensor, epilogue: Callable[[torch.Tensor, list[torch.Tensor]], torch.Tensor]=lambda acc, tile: acc, *, _launcher=_default_launcher):
    m, k = x.size()
    k2, n = y.size()
    assert k == k2, f'size mismatch {k} != {k2}'
    out = torch.zeros([m, n], dtype=torch.promote_types(x.dtype, y.dtype), device=x.device)
    split_k = 4
    k_block = helion.next_power_of_2(helion.cdiv(k, split_k))
    _BLOCK_SIZE_1 = 128
    _BLOCK_SIZE_0 = 128
    _BLOCK_SIZE_2 = k_block
    _BLOCK_SIZE_3 = 64
    _launcher(_matmul_split_k_kernel, (triton.cdiv(2304, _BLOCK_SIZE_1) * triton.cdiv(2304, _BLOCK_SIZE_0) * triton.cdiv(2304, _BLOCK_SIZE_2),), x, y, out, _BLOCK_SIZE_1, _BLOCK_SIZE_0, _BLOCK_SIZE_2, _BLOCK_SIZE_3, num_warps=8, num_stages=8)
    return out
INFO:helion.runtime.kernel:Output code: 
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

import examples.matmul_split_k as _source_module

@triton.jit
def _matmul_split_k_kernel(x, y, out, _BLOCK_SIZE_1: tl.constexpr, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_2: tl.constexpr, _BLOCK_SIZE_3: tl.constexpr):
    num_blocks_0 = tl.cdiv(2304, _BLOCK_SIZE_1)
    num_blocks_1 = tl.cdiv(2304, _BLOCK_SIZE_0)
    num_pid_m = tl.cdiv(2304, _BLOCK_SIZE_1)
    num_pid_n = tl.cdiv(2304, _BLOCK_SIZE_0)
    inner_2d_size = num_pid_m * num_pid_n
    inner_2d_pid = tl.program_id(0) % inner_2d_size
    num_pid_in_group = 2 * num_pid_n
    group_id = inner_2d_pid // num_pid_in_group
    first_pid_m = group_id * 2
    group_size_m = min(num_pid_m - first_pid_m, 2)
    pid_0 = first_pid_m + inner_2d_pid % num_pid_in_group % group_size_m
    pid_1 = inner_2d_pid % num_pid_in_group // group_size_m
    pid_2 = tl.program_id(0) // (num_blocks_0 * num_blocks_1)
    offset_1 = pid_0 * _BLOCK_SIZE_1
    indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
    offset_0 = pid_1 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    offset_2 = pid_2 * _BLOCK_SIZE_2
    acc = tl.full([_BLOCK_SIZE_0, _BLOCK_SIZE_1], 0.0, tl.float32)
    tile_end = tl.minimum(offset_2 + _BLOCK_SIZE_2, 2304)
    for offset_3 in tl.range(offset_2.to(tl.int32), tile_end.to(tl.int32), _BLOCK_SIZE_3, num_stages=3, flatten=False):
        indices_3 = offset_3 + tl.arange(0, _BLOCK_SIZE_3).to(tl.int32)
        mask_3 = indices_3 < tile_end
        acc_copy = acc
        acc_copy_0 = acc_copy
        load = tl.load(x + (indices_0[:, None] * 2304 + indices_3[None, :] * 1), mask_3[None, :], other=0)
        load_1 = tl.load(y + (indices_3[:, None] * 1 + indices_1[None, :] * 2304), mask_3[:, None], other=0)
        acc = tl.dot(load, load_1, acc=acc_copy_0, input_precision='tf32')
    eq = offset_2 == 0
    if eq:
        acc_copy_1 = acc
        acc = acc_copy_1
    tl.atomic_add(out + (indices_0[:, None] * 2304 + indices_1[None, :] * 1), acc, mask=None, sem='relaxed')

def matmul_split_k(x: torch.Tensor, y: torch.Tensor, epilogue: Callable[[torch.Tensor, list[torch.Tensor]], torch.Tensor]=lambda acc, tile: acc, *, _launcher=_default_launcher):
    m, k = x.size()
    k2, n = y.size()
    assert k == k2, f'size mismatch {k} != {k2}'
    out = torch.zeros([m, n], dtype=torch.promote_types(x.dtype, y.dtype), device=x.device)
    split_k = 4
    k_block = helion.next_power_of_2(helion.cdiv(k, split_k))
    _BLOCK_SIZE_1 = 128
    _BLOCK_SIZE_0 = 128
    _BLOCK_SIZE_2 = k_block
    _BLOCK_SIZE_3 = 64
    _launcher(_matmul_split_k_kernel, (triton.cdiv(2304, _BLOCK_SIZE_1) * triton.cdiv(2304, _BLOCK_SIZE_0) * triton.cdiv(2304, _BLOCK_SIZE_2),), x, y, out, _BLOCK_SIZE_1, _BLOCK_SIZE_0, _BLOCK_SIZE_2, _BLOCK_SIZE_3, num_warps=8, num_stages=8)
    return out
INFO:helion.runtime.kernel:Output code: 
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

import examples.matmul_split_k as _source_module

@triton.jit
def _matmul_split_k_kernel(x, y, out, _BLOCK_SIZE_1: tl.constexpr, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_2: tl.constexpr, _BLOCK_SIZE_3: tl.constexpr):
    num_blocks_0 = tl.cdiv(2304, _BLOCK_SIZE_1)
    num_blocks_1 = tl.cdiv(2304, _BLOCK_SIZE_0)
    num_pid_m = tl.cdiv(2304, _BLOCK_SIZE_1)
    num_pid_n = tl.cdiv(2304, _BLOCK_SIZE_0)
    inner_2d_size = num_pid_m * num_pid_n
    inner_2d_pid = tl.program_id(0) % inner_2d_size
    num_pid_in_group = 2 * num_pid_n
    group_id = inner_2d_pid // num_pid_in_group
    first_pid_m = group_id * 2
    group_size_m = min(num_pid_m - first_pid_m, 2)
    pid_0 = first_pid_m + inner_2d_pid % num_pid_in_group % group_size_m
    pid_1 = inner_2d_pid % num_pid_in_group // group_size_m
    pid_2 = tl.program_id(0) // (num_blocks_0 * num_blocks_1)
    offset_1 = pid_0 * _BLOCK_SIZE_1
    indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
    offset_0 = pid_1 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    offset_2 = pid_2 * _BLOCK_SIZE_2
    acc = tl.full([_BLOCK_SIZE_0, _BLOCK_SIZE_1], 0.0, tl.float32)
    tile_end = tl.minimum(offset_2 + _BLOCK_SIZE_2, 2304)
    for offset_3 in tl.range(offset_2.to(tl.int32), tile_end.to(tl.int32), _BLOCK_SIZE_3, num_stages=3, flatten=False):
        indices_3 = offset_3 + tl.arange(0, _BLOCK_SIZE_3).to(tl.int32)
        mask_3 = indices_3 < tile_end
        acc_copy = acc
        acc_copy_0 = acc_copy
        load = tl.load(x + (indices_0[:, None] * 2304 + indices_3[None, :] * 1), mask_3[None, :], other=0)
        load_1 = tl.load(y + (indices_3[:, None] * 1 + indices_1[None, :] * 2304), mask_3[:, None], other=0)
        acc = tl.dot(load, load_1, acc=acc_copy_0, input_precision='tf32')
    eq = offset_2 == 0
    if eq:
        acc_copy_1 = acc
        acc = acc_copy_1
    tl.atomic_add(out + (indices_0[:, None] * 2304 + indices_1[None, :] * 1), acc, mask=None, sem='relaxed')

def matmul_split_k(x: torch.Tensor, y: torch.Tensor, epilogue: Callable[[torch.Tensor, list[torch.Tensor]], torch.Tensor]=lambda acc, tile: acc, *, _launcher=_default_launcher):
    m, k = x.size()
    k2, n = y.size()
    assert k == k2, f'size mismatch {k} != {k2}'
    out = torch.zeros([m, n], dtype=torch.promote_types(x.dtype, y.dtype), device=x.device)
    split_k = 4
    k_block = helion.next_power_of_2(helion.cdiv(k, split_k))
    _BLOCK_SIZE_1 = 128
    _BLOCK_SIZE_0 = 128
    _BLOCK_SIZE_2 = k_block
    _BLOCK_SIZE_3 = 64
    _launcher(_matmul_split_k_kernel, (triton.cdiv(2304, _BLOCK_SIZE_1) * triton.cdiv(2304, _BLOCK_SIZE_0) * triton.cdiv(2304, _BLOCK_SIZE_2),), x, y, out, _BLOCK_SIZE_1, _BLOCK_SIZE_0, _BLOCK_SIZE_2, _BLOCK_SIZE_3, num_warps=8, num_stages=8)
    return out
 12%|        | 1/8 [26:12<3:03:29, 1572.74s/it]INFO:tritonbench.utils.triton_op:Took 0.00ms to get benchmark function for aten_matmul
INFO:tritonbench.utils.triton_op:Took 0.01ms to get benchmark function for triton_tutorial_matmul
INFO:tritonbench.utils.triton_op:Took 0.05ms to get benchmark function for matmul_partition_k
INFO:tritonbench.utils.triton_op:Took 0.00ms to get benchmark function for triton_ops_matmul
INFO:tritonbench.utils.triton_op:Took 11.02ms to get benchmark function for aten_tunableop_matmul
AUTOTUNE mm(2432x2432, 2432x2432)
strides: [2432, 1], [1, 2432]
dtypes: torch.float16, torch.float16
  mm 0.0459 ms 100.0% 
  triton_mm_16 0.0526 ms 87.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_18 0.0538 ms 85.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
  triton_mm_17 0.0551 ms 83.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_11 0.0580 ms 79.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_12 0.0674 ms 68.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
  triton_mm_10 0.0772 ms 59.4% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_14 0.0791 ms 58.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_9 0.0815 ms 56.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_7 0.0864 ms 53.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
SingleProcess AUTOTUNE benchmarking takes 0.4235 seconds and 0.4002 seconds precompiling for 20 choices
INFO:tritonbench.utils.triton_op:Took 1021.21ms to get benchmark function for pt2_triton_matmul
INFO:tritonbench.utils.triton_op:Took 0.00ms to get benchmark function for streamk_matmul
 12%|        | 1/8 [26:22<3:04:37, 1582.45s/it]
WARNING:tritonbench.utils.triton_op:Caught exception, terminating early with partial results
Traceback (most recent call last):
  File "/data/users/willfeng/helion/benchmarks/tritonbench/tritonbench/utils/triton_op.py", line 902, in run
    y_vals: Dict[str, BenchmarkOperatorMetrics] = functools.reduce(
                                                  ^^^^^^^^^^^^^^^^^
  File "/data/users/willfeng/helion/benchmarks/tritonbench/tritonbench/utils/triton_op.py", line 890, in _reduce_benchmarks
    acc[bm_name] = self._do_bench(
                   ^^^^^^^^^^^^^^^
  File "/data/users/willfeng/helion/benchmarks/tritonbench/tritonbench/utils/triton_op.py", line 1149, in _do_bench
    fn = self._get_bm_func(fn_name)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/users/willfeng/helion/benchmarks/tritonbench/tritonbench/utils/triton_op.py", line 786, in _get_bm_func
    fwd_fn = fwd_fn_lambda(*self.example_inputs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/users/willfeng/helion/benchmarks/tritonbench/tritonbench/utils/triton_op.py", line 612, in _inner
    return function(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/users/willfeng/helion/benchmarks/tritonbench/tritonbench/operators/gemm/operator.py", line 335, in pt2_cutlass_matmul
    compiled(a, b)
  File "/home/willfeng/local/pytorch-nightly/torch/_dynamo/eval_frame.py", line 816, in compile_wrapper
    raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/willfeng/local/pytorch-nightly/torch/_inductor/compile_fx.py", line 952, in _compile_fx_inner
    raise InductorError(e, currentframe()).with_traceback(
  File "/home/willfeng/local/pytorch-nightly/torch/_inductor/compile_fx.py", line 936, in _compile_fx_inner
    mb_compiled_graph = fx_codegen_and_compile(
                        ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/willfeng/local/pytorch-nightly/torch/_inductor/compile_fx.py", line 1616, in fx_codegen_and_compile
    return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/willfeng/local/pytorch-nightly/torch/_inductor/compile_fx.py", line 1400, in codegen_and_compile
    graph.run(*example_inputs)
  File "/home/willfeng/local/pytorch-nightly/torch/_inductor/graph.py", line 915, in run
    return super().run(*args)
           ^^^^^^^^^^^^^^^^^^
  File "/home/willfeng/local/pytorch-nightly/torch/fx/interpreter.py", line 174, in run
    self.env[node] = self.run_node(node)
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/willfeng/local/pytorch-nightly/torch/_inductor/graph.py", line 1595, in run_node
    result = super().run_node(n)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/willfeng/local/pytorch-nightly/torch/fx/interpreter.py", line 256, in run_node
    return getattr(self, n.op)(n.target, args, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/willfeng/local/pytorch-nightly/torch/_inductor/graph.py", line 1262, in call_function
    raise LoweringException(e, target, args, kwargs).with_traceback(
  File "/home/willfeng/local/pytorch-nightly/torch/_inductor/graph.py", line 1252, in call_function
    out = lowerings[target](*args, **kwargs)  # type: ignore[index]
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/willfeng/local/pytorch-nightly/torch/_inductor/lowering.py", line 449, in wrapped
    out = decomp_fn(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/willfeng/local/pytorch-nightly/torch/_inductor/kernel/mm.py", line 780, in tuned_mm
    and use_cutlass_template(layout, m, n, k)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/willfeng/local/pytorch-nightly/torch/_inductor/utils.py", line 1649, in use_cutlass_template
    if not try_import_cutlass():
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/willfeng/local/pytorch-nightly/torch/_inductor/codegen/cuda/cutlass_utils.py", line 146, in try_import_cutlass
    link_and_append(
  File "/home/willfeng/local/pytorch-nightly/torch/_inductor/codegen/cuda/cutlass_utils.py", line 140, in link_and_append
    os.remove(dst_link)  # remove if exists
    ^^^^^^^^^^^^^^^^^^^
torch._inductor.exc.InductorError: LoweringException: FileNotFoundError: [Errno 2] No such file or directory: '/tmp/torchinductor_willfeng/torch_cutlass/cutlass_library'
  target: aten.mm.default
  args[0]: TensorBox(StorageBox(
    InputBuffer(name='arg0_1', layout=FixedLayout('cuda:0', torch.float16, size=[2432, 2432], stride=[2432, 1]))
  ))
  args[1]: TensorBox(StorageBox(
    InputBuffer(name='arg1_1', layout=FixedLayout('cuda:0', torch.float16, size=[2432, 2432], stride=[1, 2432]))
  ))

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

Removed 2 outliers from 634 samples
Removed 2 outliers from 633 samples
Removed 5 outliers from 628 samples
Removed 1 outliers from 429 samples
Traceback (most recent call last):
  File "/data/users/willfeng/helion/benchmarks/run.py", line 537, in <module>
    main()
  File "/data/users/willfeng/helion/benchmarks/run.py", line 533, in main
    run_kernel(kernel_name, tritonbench_args.copy(), input_shard_info)
  File "/data/users/willfeng/helion/benchmarks/run.py", line 245, in run_kernel
    run_kernel_variants(
  File "/data/users/willfeng/helion/benchmarks/run.py", line 442, in run_kernel_variants
    op.run(warmup=warmup, rep=rep)
  File "/data/users/willfeng/helion/benchmarks/tritonbench/tritonbench/utils/triton_op.py", line 902, in run
    y_vals: Dict[str, BenchmarkOperatorMetrics] = functools.reduce(
                                                  ^^^^^^^^^^^^^^^^^
  File "/data/users/willfeng/helion/benchmarks/tritonbench/tritonbench/utils/triton_op.py", line 890, in _reduce_benchmarks
    acc[bm_name] = self._do_bench(
                   ^^^^^^^^^^^^^^^
  File "/data/users/willfeng/helion/benchmarks/tritonbench/tritonbench/utils/triton_op.py", line 1149, in _do_bench
    fn = self._get_bm_func(fn_name)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/users/willfeng/helion/benchmarks/tritonbench/tritonbench/utils/triton_op.py", line 786, in _get_bm_func
    fwd_fn = fwd_fn_lambda(*self.example_inputs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/users/willfeng/helion/benchmarks/tritonbench/tritonbench/utils/triton_op.py", line 612, in _inner
    return function(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/users/willfeng/helion/benchmarks/tritonbench/tritonbench/operators/gemm/operator.py", line 335, in pt2_cutlass_matmul
    compiled(a, b)
  File "/home/willfeng/local/pytorch-nightly/torch/_dynamo/eval_frame.py", line 816, in compile_wrapper
    raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/willfeng/local/pytorch-nightly/torch/_inductor/compile_fx.py", line 952, in _compile_fx_inner
    raise InductorError(e, currentframe()).with_traceback(
  File "/home/willfeng/local/pytorch-nightly/torch/_inductor/compile_fx.py", line 936, in _compile_fx_inner
    mb_compiled_graph = fx_codegen_and_compile(
                        ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/willfeng/local/pytorch-nightly/torch/_inductor/compile_fx.py", line 1616, in fx_codegen_and_compile
    return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/willfeng/local/pytorch-nightly/torch/_inductor/compile_fx.py", line 1400, in codegen_and_compile
    graph.run(*example_inputs)
  File "/home/willfeng/local/pytorch-nightly/torch/_inductor/graph.py", line 915, in run
    return super().run(*args)
           ^^^^^^^^^^^^^^^^^^
  File "/home/willfeng/local/pytorch-nightly/torch/fx/interpreter.py", line 174, in run
    self.env[node] = self.run_node(node)
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/willfeng/local/pytorch-nightly/torch/_inductor/graph.py", line 1595, in run_node
    result = super().run_node(n)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/willfeng/local/pytorch-nightly/torch/fx/interpreter.py", line 256, in run_node
    return getattr(self, n.op)(n.target, args, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/willfeng/local/pytorch-nightly/torch/_inductor/graph.py", line 1262, in call_function
    raise LoweringException(e, target, args, kwargs).with_traceback(
  File "/home/willfeng/local/pytorch-nightly/torch/_inductor/graph.py", line 1252, in call_function
    out = lowerings[target](*args, **kwargs)  # type: ignore[index]
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/willfeng/local/pytorch-nightly/torch/_inductor/lowering.py", line 449, in wrapped
    out = decomp_fn(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/willfeng/local/pytorch-nightly/torch/_inductor/kernel/mm.py", line 780, in tuned_mm
    and use_cutlass_template(layout, m, n, k)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/willfeng/local/pytorch-nightly/torch/_inductor/utils.py", line 1649, in use_cutlass_template
    if not try_import_cutlass():
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/willfeng/local/pytorch-nightly/torch/_inductor/codegen/cuda/cutlass_utils.py", line 146, in try_import_cutlass
    link_and_append(
  File "/home/willfeng/local/pytorch-nightly/torch/_inductor/codegen/cuda/cutlass_utils.py", line 140, in link_and_append
    os.remove(dst_link)  # remove if exists
    ^^^^^^^^^^^^^^^^^^^
torch._inductor.exc.InductorError: LoweringException: FileNotFoundError: [Errno 2] No such file or directory: '/tmp/torchinductor_willfeng/torch_cutlass/cutlass_library'
  target: aten.mm.default
  args[0]: TensorBox(StorageBox(
    InputBuffer(name='arg0_1', layout=FixedLayout('cuda:0', torch.float16, size=[2432, 2432], stride=[2432, 1]))
  ))
  args[1]: TensorBox(StorageBox(
    InputBuffer(name='arg1_1', layout=FixedLayout('cuda:0', torch.float16, size=[2432, 2432], stride=[1, 2432]))
  ))

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

