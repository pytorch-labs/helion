This file is automatically generated by assertExpectedJournal calls in test_indexing.py.
Update expected outputs by running tests with the EXPECTTEST_ACCEPT=1 environment variable set.

--- assertExpectedJournal(TestIndexing.test_arange)
from __future__ import annotations

import torch
import triton
import triton.language as tl

@triton.jit
def _arange_kernel(out, out_stride_0, length, _BLOCK_SIZE_0: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    mask_0 = indices_0 < length
    tl.store(out + indices_0 * out_stride_0, indices_0, mask_0)

def arange(length: int, device: torch.device):
    out = torch.empty([length], dtype=torch.int32, device=device)
    _BLOCK_SIZE_0 = 32
    _arange_kernel[triton.cdiv(length, _BLOCK_SIZE_0),](out, out.stride(0), length, _BLOCK_SIZE_0, num_warps=4, num_stages=3)
    return out

def _arange_make_precompiler(length: int, device: torch.device):
    out = torch.empty([length], dtype=torch.int32, device=device)
    _BLOCK_SIZE_0 = 32
    from helion.runtime.precompile_shim import make_precompiler
    return make_precompiler(_arange_kernel)(out, out.stride(0), length, _BLOCK_SIZE_0, num_warps=4, num_stages=3)

--- assertExpectedJournal(TestIndexing.test_arange_three_args_step)
from __future__ import annotations

import torch
import triton
import triton.language as tl

@triton.jit
def _arange_three_args_step_kernel(out, out_size_0, out_stride_0, _BLOCK_SIZE_0: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    mask_0 = indices_0 < out_size_0
    mul = 2 * offset_0
    iota = (mul + 2 * tl.arange(0, _BLOCK_SIZE_0)).to(tl.int64)
    v_0 = iota.to(tl.int32)
    tl.store(out + indices_0 * out_stride_0, v_0, mask_0)

def arange_three_args_step(x: torch.Tensor):
    out = torch.zeros([x.size(0) // 2], dtype=torch.int32, device=x.device)
    _BLOCK_SIZE_0 = 8
    _arange_three_args_step_kernel[triton.cdiv(out.size(0), _BLOCK_SIZE_0),](out, out.size(0), out.stride(0), _BLOCK_SIZE_0, num_warps=4, num_stages=3)
    return out

def _arange_three_args_step_make_precompiler(x: torch.Tensor):
    out = torch.zeros([x.size(0) // 2], dtype=torch.int32, device=x.device)
    _BLOCK_SIZE_0 = 8
    from helion.runtime.precompile_shim import make_precompiler
    return make_precompiler(_arange_three_args_step_kernel)(out, out.size(0), out.stride(0), _BLOCK_SIZE_0, num_warps=4, num_stages=3)

--- assertExpectedJournal(TestIndexing.test_mask_load)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from torch._inductor.runtime.triton_compat import libdevice

@triton.jit
def _masked_load_kernel(x, out, x_size_0, out_stride_0, x_stride_0, _BLOCK_SIZE_0: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    mask_0 = indices_0 < x_size_0
    v_0 = tl.full([], 2, tl.int32)
    v_1 = indices_0 % v_0
    v_2 = tl.full([], 0, tl.int32)
    v_3 = v_1 != v_2
    v_4 = libdevice.signbit(v_1) != 0 if v_1.dtype is tl.float32 else v_1 < 0
    v_5 = libdevice.signbit(v_0) != 0 if v_0.dtype is tl.float32 else v_0 < 0
    v_6 = v_4 != v_5
    v_7 = v_3 & v_6
    v_8 = v_1 + v_0
    v_9 = tl.where(v_7, v_8, v_1)
    v_10 = tl.full([], 0, tl.int32)
    v_11 = v_9 == v_10
    load = tl.load(x + indices_0 * x_stride_0, mask_0 & v_11, other=0)
    tl.store(out + indices_0 * out_stride_0, load, mask_0)

def masked_load(x: torch.Tensor):
    out = torch.zeros_like(x)
    _BLOCK_SIZE_0 = 16
    _masked_load_kernel[triton.cdiv(x.size(0), _BLOCK_SIZE_0),](x, out, x.size(0), out.stride(0), x.stride(0), _BLOCK_SIZE_0, num_warps=4, num_stages=3)
    return out

def _masked_load_make_precompiler(x: torch.Tensor):
    out = torch.zeros_like(x)
    _BLOCK_SIZE_0 = 16
    from helion.runtime.precompile_shim import make_precompiler
    return make_precompiler(_masked_load_kernel)(x, out, x.size(0), out.stride(0), x.stride(0), _BLOCK_SIZE_0, num_warps=4, num_stages=3)

--- assertExpectedJournal(TestIndexing.test_mask_store)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from torch._inductor.runtime.triton_compat import libdevice

@triton.jit
def _masked_store_kernel(x, out, x_size_0, out_stride_0, x_stride_0, _BLOCK_SIZE_0: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    mask_0 = indices_0 < x_size_0
    load = tl.load(x + indices_0 * x_stride_0, mask_0, other=0)
    v_0 = tl.full([], 2, tl.int32)
    v_1 = indices_0 % v_0
    v_2 = tl.full([], 0, tl.int32)
    v_3 = v_1 != v_2
    v_4 = libdevice.signbit(v_1) != 0 if v_1.dtype is tl.float32 else v_1 < 0
    v_5 = libdevice.signbit(v_0) != 0 if v_0.dtype is tl.float32 else v_0 < 0
    v_6 = v_4 != v_5
    v_7 = v_3 & v_6
    v_8 = v_1 + v_0
    v_9 = tl.where(v_7, v_8, v_1)
    v_10 = tl.full([], 0, tl.int32)
    v_11 = v_9 == v_10
    tl.store(out + indices_0 * out_stride_0, load, mask_0 & v_11)

def masked_store(x: torch.Tensor):
    out = torch.zeros_like(x)
    _BLOCK_SIZE_0 = 16
    _masked_store_kernel[triton.cdiv(x.size(0), _BLOCK_SIZE_0),](x, out, x.size(0), out.stride(0), x.stride(0), _BLOCK_SIZE_0, num_warps=4, num_stages=3)
    return out

def _masked_store_make_precompiler(x: torch.Tensor):
    out = torch.zeros_like(x)
    _BLOCK_SIZE_0 = 16
    from helion.runtime.precompile_shim import make_precompiler
    return make_precompiler(_masked_store_kernel)(x, out, x.size(0), out.stride(0), x.stride(0), _BLOCK_SIZE_0, num_warps=4, num_stages=3)

--- assertExpectedJournal(TestIndexing.test_pairwise_add)
from __future__ import annotations

import torch
import triton
import triton.language as tl

@triton.jit
def _pairwise_add_kernel(out, x, out_size_0, out_stride_0, x_stride_0, _BLOCK_SIZE_0: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    mask_0 = indices_0 < out_size_0
    load = tl.load(x + indices_0 * x_stride_0, mask_0, other=0)
    v_0 = tl.full([], 1, tl.int32)
    v_1 = indices_0 + v_0
    load_1 = tl.load(x + v_1 * x_stride_0, mask_0, other=0)
    v_2 = load + load_1
    tl.store(out + indices_0 * out_stride_0, v_2, mask_0)

def pairwise_add(x: torch.Tensor):
    out = x.new_empty([x.size(0) - 1])
    _BLOCK_SIZE_0 = 32
    _pairwise_add_kernel[triton.cdiv(out.size(0), _BLOCK_SIZE_0),](out, x, out.size(0), out.stride(0), x.stride(0), _BLOCK_SIZE_0, num_warps=4, num_stages=3)
    return out

def _pairwise_add_make_precompiler(x: torch.Tensor):
    out = x.new_empty([x.size(0) - 1])
    _BLOCK_SIZE_0 = 32
    from helion.runtime.precompile_shim import make_precompiler
    return make_precompiler(_pairwise_add_kernel)(out, x, out.size(0), out.stride(0), x.stride(0), _BLOCK_SIZE_0, num_warps=4, num_stages=3)

