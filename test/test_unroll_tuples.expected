This file is automatically generated by assertExpectedJournal calls in test_unroll_tuples.py.
Update expected outputs by running tests with the EXPECTTEST_ACCEPT=1 environment variable set.

--- assertExpectedJournal(TestUnrollTuples.test_basic_tuple_addition)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _kernel_tuple_addition_kernel(out, a_shared_tuple_item_0, a_shared_tuple_item_1, a_shared_tuple_item_2, out_size_0, a_shared_tuple_item_0_stride_0, a_shared_tuple_item_1_stride_0, a_shared_tuple_item_2_stride_0, out_stride_0, _BLOCK_SIZE_0: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    mask_0 = indices_0 < out_size_0
    acc = tl.full([_BLOCK_SIZE_0], 0, tl.float32)
    load = tl.load(a_shared_tuple_item_0 + indices_0 * a_shared_tuple_item_0_stride_0, mask_0, other=0)
    v_0 = acc + load
    load_1 = tl.load(a_shared_tuple_item_1 + indices_0 * a_shared_tuple_item_1_stride_0, mask_0, other=0)
    v_1 = v_0 + load_1
    load_2 = tl.load(a_shared_tuple_item_2 + indices_0 * a_shared_tuple_item_2_stride_0, mask_0, other=0)
    v_2 = v_1 + load_2
    tl.store(out + indices_0 * out_stride_0, v_2, mask_0)

def kernel_tuple_addition(a_shared_tuple: tuple[torch.Tensor, ...], *, _launcher=_default_launcher):
    """Basic test: iterate over a tuple of tensors and sum them."""
    out = torch.empty_like(a_shared_tuple[0])
    _BLOCK_SIZE_0 = 32
    _launcher(_kernel_tuple_addition_kernel, (triton.cdiv(out.size(0), _BLOCK_SIZE_0),), out, a_shared_tuple[0], a_shared_tuple[1], a_shared_tuple[2], out.size(0), a_shared_tuple[0].stride(0), a_shared_tuple[1].stride(0), a_shared_tuple[2].stride(0), out.stride(0), _BLOCK_SIZE_0, num_warps=4, num_stages=3)
    return out

--- assertExpectedJournal(TestUnrollTuples.test_constants_iteration)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _kernel_constants_iteration_kernel(x, result, x_size_0, result_stride_0, x_stride_0, _BLOCK_SIZE_0: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    mask_0 = indices_0 < x_size_0
    acc = tl.full([_BLOCK_SIZE_0], 0, tl.float32)
    load = tl.load(x + indices_0 * x_stride_0, mask_0, other=0)
    v_0 = 1.0
    v_1 = load * v_0
    v_2 = acc + v_1
    load_1 = tl.load(x + indices_0 * x_stride_0, mask_0, other=0)
    v_3 = 2.0
    v_4 = load_1 * v_3
    v_5 = v_2 + v_4
    load_2 = tl.load(x + indices_0 * x_stride_0, mask_0, other=0)
    v_6 = 3.0
    v_7 = load_2 * v_6
    v_8 = v_5 + v_7
    tl.store(result + indices_0 * result_stride_0, v_8, mask_0)

def kernel_constants_iteration(x: torch.Tensor, *, _launcher=_default_launcher):
    """Test iteration over a tuple/list of constants."""
    result = torch.zeros_like(x)
    _BLOCK_SIZE_0 = 32
    _launcher(_kernel_constants_iteration_kernel, (triton.cdiv(x.size(0), _BLOCK_SIZE_0),), x, result, x.size(0), result.stride(0), x.stride(0), _BLOCK_SIZE_0, num_warps=4, num_stages=3)
    return result

--- assertExpectedJournal(TestUnrollTuples.test_enumerate_constants)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _kernel_enumerate_constants_kernel(x, result, x_size_0, result_stride_0, x_stride_0, _BLOCK_SIZE_0: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    mask_0 = indices_0 < x_size_0
    acc = tl.full([_BLOCK_SIZE_0], 0, tl.float32)
    load = tl.load(x + indices_0 * x_stride_0, mask_0, other=0)
    v_0 = 2.0
    v_1 = load * v_0
    v_2 = 0.0
    v_3 = v_1 * v_2
    v_4 = acc + v_3
    load_1 = tl.load(x + indices_0 * x_stride_0, mask_0, other=0)
    v_5 = 3.0
    v_6 = load_1 * v_5
    v_7 = 1.0
    v_8 = v_6 * v_7
    v_9 = v_4 + v_8
    load_2 = tl.load(x + indices_0 * x_stride_0, mask_0, other=0)
    v_10 = 4.0
    v_11 = load_2 * v_10
    v_12 = 2.0
    v_13 = v_11 * v_12
    v_14 = v_9 + v_13
    tl.store(result + indices_0 * result_stride_0, v_14, mask_0)

def kernel_enumerate_constants(x: torch.Tensor, *, _launcher=_default_launcher):
    """Test enumerate over constants."""
    result = torch.zeros_like(x)
    _BLOCK_SIZE_0 = 32
    _launcher(_kernel_enumerate_constants_kernel, (triton.cdiv(x.size(0), _BLOCK_SIZE_0),), x, result, x.size(0), result.stride(0), x.stride(0), _BLOCK_SIZE_0, num_warps=4, num_stages=3)
    return result

--- assertExpectedJournal(TestUnrollTuples.test_enumerate_iteration)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _kernel_enumerate_iteration_kernel(tensors_item_2, tensors_item_0, tensors_item_1, result, tensors_item_2_size_0, result_stride_0, tensors_item_0_stride_0, tensors_item_1_stride_0, tensors_item_2_stride_0, _BLOCK_SIZE_0: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    mask_0 = indices_0 < tensors_item_2_size_0
    acc = tl.full([_BLOCK_SIZE_0], 0, tl.float32)
    load = tl.load(tensors_item_0 + indices_0 * tensors_item_0_stride_0, mask_0, other=0)
    v_0 = 1.0
    v_1 = load * v_0
    v_2 = acc + v_1
    load_1 = tl.load(tensors_item_1 + indices_0 * tensors_item_1_stride_0, mask_0, other=0)
    v_3 = 2.0
    v_4 = load_1 * v_3
    v_5 = v_2 + v_4
    load_2 = tl.load(tensors_item_2 + indices_0 * tensors_item_2_stride_0, mask_0, other=0)
    v_6 = 3.0
    v_7 = load_2 * v_6
    v_8 = v_5 + v_7
    tl.store(result + indices_0 * result_stride_0, v_8, mask_0)

def kernel_enumerate_iteration(tensors: tuple[torch.Tensor, torch.Tensor, torch.Tensor], *, _launcher=_default_launcher):
    """Test iteration using enumerate over tensors."""
    result = torch.zeros_like(tensors[0])
    _BLOCK_SIZE_0 = 32
    _launcher(_kernel_enumerate_iteration_kernel, (triton.cdiv(tensors[2].size(0), _BLOCK_SIZE_0),), tensors[2], tensors[0], tensors[1], result, tensors[2].size(0), result.stride(0), tensors[0].stride(0), tensors[1].stride(0), tensors[2].stride(0), _BLOCK_SIZE_0, num_warps=4, num_stages=3)
    return result

--- assertExpectedJournal(TestUnrollTuples.test_enumerate_with_start)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _kernel_enumerate_with_start_kernel(result, tensors_item_0, tensors_item_1, result_size_0, result_stride_0, tensors_item_0_stride_0, tensors_item_1_stride_0, _BLOCK_SIZE_0: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    mask_0 = indices_0 < result_size_0
    acc = tl.full([_BLOCK_SIZE_0], 0, tl.float32)
    load = tl.load(tensors_item_0 + indices_0 * tensors_item_0_stride_0, mask_0, other=0)
    v_0 = 5.0
    v_1 = load * v_0
    v_2 = acc + v_1
    load_1 = tl.load(tensors_item_1 + indices_0 * tensors_item_1_stride_0, mask_0, other=0)
    v_3 = 6.0
    v_4 = load_1 * v_3
    v_5 = v_2 + v_4
    tl.store(result + indices_0 * result_stride_0, v_5, mask_0)

def kernel_enumerate_with_start(tensors: tuple[torch.Tensor, torch.Tensor], *, _launcher=_default_launcher):
    """Test enumerate with custom start value."""
    result = torch.zeros_like(tensors[0])
    _BLOCK_SIZE_0 = 32
    _launcher(_kernel_enumerate_with_start_kernel, (triton.cdiv(result.size(0), _BLOCK_SIZE_0),), result, tensors[0], tensors[1], result.size(0), result.stride(0), tensors[0].stride(0), tensors[1].stride(0), _BLOCK_SIZE_0, num_warps=4, num_stages=3)
    return result

--- assertExpectedJournal(TestUnrollTuples.test_list_constants_iteration)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _kernel_list_constants_iteration_kernel(x, result, x_size_0, result_stride_0, x_stride_0, _BLOCK_SIZE_0: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    mask_0 = indices_0 < x_size_0
    acc = tl.full([_BLOCK_SIZE_0], 0, tl.float32)
    load = tl.load(x + indices_0 * x_stride_0, mask_0, other=0)
    v_0 = 0.5
    v_1 = load * v_0
    v_2 = acc + v_1
    load_1 = tl.load(x + indices_0 * x_stride_0, mask_0, other=0)
    v_3 = 1.5
    v_4 = load_1 * v_3
    v_5 = v_2 + v_4
    load_2 = tl.load(x + indices_0 * x_stride_0, mask_0, other=0)
    v_6 = 2.5
    v_7 = load_2 * v_6
    v_8 = v_5 + v_7
    tl.store(result + indices_0 * result_stride_0, v_8, mask_0)

def kernel_list_constants_iteration(x: torch.Tensor, *, _launcher=_default_launcher):
    """Test iteration over a list of constants."""
    result = torch.zeros_like(x)
    _BLOCK_SIZE_0 = 32
    _launcher(_kernel_list_constants_iteration_kernel, (triton.cdiv(x.size(0), _BLOCK_SIZE_0),), x, result, x.size(0), result.stride(0), x.stride(0), _BLOCK_SIZE_0, num_warps=4, num_stages=3)
    return result

--- assertExpectedJournal(TestUnrollTuples.test_mixed_constants_and_tensors)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _kernel_mixed_constants_and_tensors_kernel(result, tensors_item_0, tensors_item_1, result_size_0, result_stride_0, tensors_item_0_stride_0, tensors_item_1_stride_0, constants_item_0, constants_item_1, _BLOCK_SIZE_0: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    mask_0 = indices_0 < result_size_0
    acc = tl.full([_BLOCK_SIZE_0], 0, tl.float32)
    load = tl.load(tensors_item_0 + indices_0 * tensors_item_0_stride_0, mask_0, other=0)
    v_0 = acc + load
    load_1 = tl.load(tensors_item_1 + indices_0 * tensors_item_1_stride_0, mask_0, other=0)
    v_1 = v_0 + load_1
    v_2 = constants_item_0.to(tl.float32)
    v_3 = v_1 * v_2
    v_4 = constants_item_1.to(tl.float32)
    v_5 = v_3 * v_4
    tl.store(result + indices_0 * result_stride_0, v_5, mask_0)

def kernel_mixed_constants_and_tensors(tensors: tuple[torch.Tensor, torch.Tensor], constants: tuple[int, int], *, _launcher=_default_launcher):
    """Test mixed iteration over both tensors and constants."""
    result = torch.zeros_like(tensors[0])
    _BLOCK_SIZE_0 = 32
    _launcher(_kernel_mixed_constants_and_tensors_kernel, (triton.cdiv(result.size(0), _BLOCK_SIZE_0),), result, tensors[0], tensors[1], result.size(0), result.stride(0), tensors[0].stride(0), tensors[1].stride(0), constants[0], constants[1], _BLOCK_SIZE_0, num_warps=4, num_stages=3)
    return result

--- assertExpectedJournal(TestUnrollTuples.test_nested_tuple_iteration)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _kernel_nested_tuple_iteration_kernel(result, a_tuple_item_0, a_tuple_item_1, b_tuple_item_0, b_tuple_item_1, result_size_0, a_tuple_item_0_stride_0, a_tuple_item_1_stride_0, b_tuple_item_0_stride_0, b_tuple_item_1_stride_0, result_stride_0, _BLOCK_SIZE_0: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    mask_0 = indices_0 < result_size_0
    temp = tl.full([_BLOCK_SIZE_0], 0, tl.float32)
    load = tl.load(a_tuple_item_0 + indices_0 * a_tuple_item_0_stride_0, mask_0, other=0)
    v_0 = temp + load
    load_1 = tl.load(a_tuple_item_1 + indices_0 * a_tuple_item_1_stride_0, mask_0, other=0)
    v_1 = v_0 + load_1
    load_2 = tl.load(b_tuple_item_0 + indices_0 * b_tuple_item_0_stride_0, mask_0, other=0)
    v_2 = v_1 * load_2
    load_3 = tl.load(b_tuple_item_1 + indices_0 * b_tuple_item_1_stride_0, mask_0, other=0)
    v_3 = v_2 * load_3
    tl.store(result + indices_0 * result_stride_0, v_3, mask_0)

def kernel_nested_tuple_iteration(a_tuple: tuple[torch.Tensor, torch.Tensor], b_tuple: tuple[torch.Tensor, torch.Tensor], *, _launcher=_default_launcher):
    """Test nested iteration over multiple tuples."""
    result = torch.zeros_like(a_tuple[0])
    _BLOCK_SIZE_0 = 64
    _launcher(_kernel_nested_tuple_iteration_kernel, (triton.cdiv(result.size(0), _BLOCK_SIZE_0),), result, a_tuple[0], a_tuple[1], b_tuple[0], b_tuple[1], result.size(0), a_tuple[0].stride(0), a_tuple[1].stride(0), b_tuple[0].stride(0), b_tuple[1].stride(0), result.stride(0), _BLOCK_SIZE_0, num_warps=4, num_stages=3)
    return result

--- assertExpectedJournal(TestUnrollTuples.test_single_element_tuple)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _kernel_tuple_addition_kernel(out, a_shared_tuple_item_0, out_size_0, a_shared_tuple_item_0_stride_0, out_stride_0, _BLOCK_SIZE_0: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    mask_0 = indices_0 < out_size_0
    acc = tl.full([_BLOCK_SIZE_0], 0, tl.float32)
    load = tl.load(a_shared_tuple_item_0 + indices_0 * a_shared_tuple_item_0_stride_0, mask_0, other=0)
    v_0 = acc + load
    tl.store(out + indices_0 * out_stride_0, v_0, mask_0)

def kernel_tuple_addition(a_shared_tuple: tuple[torch.Tensor, ...], *, _launcher=_default_launcher):
    """Basic test: iterate over a tuple of tensors and sum them."""
    out = torch.empty_like(a_shared_tuple[0])
    _BLOCK_SIZE_0 = 16
    _launcher(_kernel_tuple_addition_kernel, (triton.cdiv(out.size(0), _BLOCK_SIZE_0),), out, a_shared_tuple[0], out.size(0), a_shared_tuple[0].stride(0), out.stride(0), _BLOCK_SIZE_0, num_warps=4, num_stages=3)
    return out

--- assertExpectedJournal(TestUnrollTuples.test_static_range_iteration)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _kernel_static_range_iteration_kernel(x, result, x_size_0, result_stride_0, x_stride_0, _BLOCK_SIZE_0: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    mask_0 = indices_0 < x_size_0
    acc = tl.full([_BLOCK_SIZE_0], 0, tl.float32)
    load = tl.load(x + indices_0 * x_stride_0, mask_0, other=0)
    v_0 = 1.0
    v_1 = load * v_0
    v_2 = acc + v_1
    load_1 = tl.load(x + indices_0 * x_stride_0, mask_0, other=0)
    v_3 = 2.0
    v_4 = load_1 * v_3
    v_5 = v_2 + v_4
    load_2 = tl.load(x + indices_0 * x_stride_0, mask_0, other=0)
    v_6 = 3.0
    v_7 = load_2 * v_6
    v_8 = v_5 + v_7
    load_3 = tl.load(x + indices_0 * x_stride_0, mask_0, other=0)
    v_9 = 4.0
    v_10 = load_3 * v_9
    v_11 = v_8 + v_10
    tl.store(result + indices_0 * result_stride_0, v_11, mask_0)

def kernel_static_range_iteration(x: torch.Tensor, *, _launcher=_default_launcher):
    """Test iteration using hl.static_range."""
    result = torch.zeros_like(x)
    _BLOCK_SIZE_0 = 32
    _launcher(_kernel_static_range_iteration_kernel, (triton.cdiv(x.size(0), _BLOCK_SIZE_0),), x, result, x.size(0), result.stride(0), x.stride(0), _BLOCK_SIZE_0, num_warps=4, num_stages=3)
    return result

--- assertExpectedJournal(TestUnrollTuples.test_static_range_with_start)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _kernel_static_range_with_start_kernel(x, result, x_size_0, result_stride_0, x_stride_0, _BLOCK_SIZE_0: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    mask_0 = indices_0 < x_size_0
    acc = tl.full([_BLOCK_SIZE_0], 0, tl.float32)
    load = tl.load(x + indices_0 * x_stride_0, mask_0, other=0)
    v_0 = 2.0
    v_1 = load * v_0
    v_2 = acc + v_1
    load_1 = tl.load(x + indices_0 * x_stride_0, mask_0, other=0)
    v_3 = 3.0
    v_4 = load_1 * v_3
    v_5 = v_2 + v_4
    load_2 = tl.load(x + indices_0 * x_stride_0, mask_0, other=0)
    v_6 = 4.0
    v_7 = load_2 * v_6
    v_8 = v_5 + v_7
    tl.store(result + indices_0 * result_stride_0, v_8, mask_0)

def kernel_static_range_with_start(x: torch.Tensor, *, _launcher=_default_launcher):
    """Test static_range with start parameter."""
    result = torch.zeros_like(x)
    _BLOCK_SIZE_0 = 32
    _launcher(_kernel_static_range_with_start_kernel, (triton.cdiv(x.size(0), _BLOCK_SIZE_0),), x, result, x.size(0), result.stride(0), x.stride(0), _BLOCK_SIZE_0, num_warps=4, num_stages=3)
    return result

--- assertExpectedJournal(TestUnrollTuples.test_tuple_with_scaling_factors)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _kernel_tuple_with_scaling_kernel(tensor3, tensor1, tensor2, output, tensor3_size_0, output_stride_0, tensor1_stride_0, tensor2_stride_0, tensor3_stride_0, scale1, scale2, scale3, _BLOCK_SIZE_0: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    mask_0 = indices_0 < tensor3_size_0
    temp = tl.full([_BLOCK_SIZE_0], 0, tl.float32)
    load = tl.load(tensor1 + indices_0 * tensor1_stride_0, mask_0, other=0)
    v_0 = load * scale1
    v_1 = temp + v_0
    load_1 = tl.load(tensor2 + indices_0 * tensor2_stride_0, mask_0, other=0)
    v_2 = load_1 * scale2
    v_3 = v_1 + v_2
    load_2 = tl.load(tensor3 + indices_0 * tensor3_stride_0, mask_0, other=0)
    v_4 = load_2 * scale3
    v_5 = v_3 + v_4
    tl.store(output + indices_0 * output_stride_0, v_5, mask_0)

def kernel_tuple_with_scaling(tensor1: torch.Tensor, tensor2: torch.Tensor, tensor3: torch.Tensor, scale1: float, scale2: float, scale3: float, *, _launcher=_default_launcher):
    """Test iteration over tensors with corresponding scalar multipliers."""
    output = torch.zeros_like(tensor1)
    _BLOCK_SIZE_0 = 64
    _launcher(_kernel_tuple_with_scaling_kernel, (triton.cdiv(tensor3.size(0), _BLOCK_SIZE_0),), tensor3, tensor1, tensor2, output, tensor3.size(0), output.stride(0), tensor1.stride(0), tensor2.stride(0), tensor3.stride(0), scale1, scale2, scale3, _BLOCK_SIZE_0, num_warps=4, num_stages=3)
    return output

--- assertExpectedJournal(TestUnrollTuples.test_zip_iteration)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _kernel_zip_iteration_kernel(result, tensors_a_item_0, tensors_b_item_0, tensors_a_item_1, tensors_b_item_1, result_size_0, result_stride_0, tensors_a_item_0_stride_0, tensors_a_item_1_stride_0, tensors_b_item_0_stride_0, tensors_b_item_1_stride_0, _BLOCK_SIZE_0: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    mask_0 = indices_0 < result_size_0
    acc = tl.full([_BLOCK_SIZE_0], 0, tl.float32)
    load = tl.load(tensors_a_item_0 + indices_0 * tensors_a_item_0_stride_0, mask_0, other=0)
    load_1 = tl.load(tensors_b_item_0 + indices_0 * tensors_b_item_0_stride_0, mask_0, other=0)
    v_0 = load * load_1
    v_1 = acc + v_0
    load_2 = tl.load(tensors_a_item_1 + indices_0 * tensors_a_item_1_stride_0, mask_0, other=0)
    load_3 = tl.load(tensors_b_item_1 + indices_0 * tensors_b_item_1_stride_0, mask_0, other=0)
    v_2 = load_2 * load_3
    v_3 = v_1 + v_2
    tl.store(result + indices_0 * result_stride_0, v_3, mask_0)

def kernel_zip_iteration(tensors_a: tuple[torch.Tensor, torch.Tensor], tensors_b: tuple[torch.Tensor, torch.Tensor], *, _launcher=_default_launcher):
    """Test iteration over zip of tuples."""
    result = torch.zeros_like(tensors_a[0])
    _BLOCK_SIZE_0 = 64
    _launcher(_kernel_zip_iteration_kernel, (triton.cdiv(result.size(0), _BLOCK_SIZE_0),), result, tensors_a[0], tensors_b[0], tensors_a[1], tensors_b[1], result.size(0), result.stride(0), tensors_a[0].stride(0), tensors_a[1].stride(0), tensors_b[0].stride(0), tensors_b[1].stride(0), _BLOCK_SIZE_0, num_warps=4, num_stages=3)
    return result
